<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


















  
  
  <link rel="stylesheet" href="/lib/fancybox/source/jquery.fancybox.css">







<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.0.1',
    sidebar: {"position":"left","display":"post","offset":10,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="这篇文章记录词向量的发展历程，包括tf-idf、word2vec、GloVe、ELMo、OpenAI GPT以及Bert，只记录个人认为比较核心的内容，以及一些值得思考的边角细节。">
<meta name="keywords" content="NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP词向量发展历程">
<meta property="og:url" content="http://anery.github.io/posts/a71e8abb.html">
<meta property="og:site_name" content="ymmy">
<meta property="og:description" content="这篇文章记录词向量的发展历程，包括tf-idf、word2vec、GloVe、ELMo、OpenAI GPT以及Bert，只记录个人认为比较核心的内容，以及一些值得思考的边角细节。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200225165605690.png#pic_center">
<meta property="og:image" content="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200216224934.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200216225025.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200216233258.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200218230527.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200222142447.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200222154051.png">
<meta property="og:updated_time" content="2020-02-25T12:40:11.491Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP词向量发展历程">
<meta name="twitter:description" content="这篇文章记录词向量的发展历程，包括tf-idf、word2vec、GloVe、ELMo、OpenAI GPT以及Bert，只记录个人认为比较核心的内容，以及一些值得思考的边角细节。">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20200225165605690.png#pic_center">



  <link rel="alternate" href="/atom.xml" title="ymmy" type="application/atom+xml">



  
  
  <link rel="canonical" href="http://anery.github.io/posts/a71e8abb">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>NLP词向量发展历程 | ymmy</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ymmy</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://anery.github.io/posts/a71e8abb.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yue Yuan">
      <meta itemprop="description" content="Take it easy">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ymmy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">NLP词向量发展历程

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2020-02-25 17:08:52 / 修改时间：20:40:11" itemprop="dateCreated datePublished" datetime="2020-02-25T17:08:52+08:00">2020-02-25</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/posts/a71e8abb.html#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/posts/a71e8abb.html" itemprop="commentCount"></span>
                </a>
              </span>
            
          

           
          
            <span id="/posts/a71e8abb.html" class="leancloud_visitors" data-flag-title="NLP词向量发展历程">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              
                <span class="post-meta-item-text">阅读次数：</span>
              
                <span class="leancloud-visitors-count"></span>
            </span>
          
		  
		  
            <div class="post-wordcount">
              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  3,670 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  13
                </span>
              
            </div>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这篇文章记录词向量的发展历程，包括<strong>tf-idf、word2vec、GloVe、ELMo、OpenAI GPT</strong>以及<strong>Bert</strong>，只记录个人认为比较核心的内容，以及一些值得思考的边角细节。</p>
<a id="more"></a>
<h1 id="1、tf-idf" class="heading-control"><a href="#1、tf-idf" class="headerlink" title="1、tf-idf"></a>1、tf-idf<a class="heading-anchor" href="#1、tf-idf" aria-hidden="true"></a></h1><p>tf-idf是一种比较传统的文本表示方法，它首先为每个词计算出一个值，再组成向量来表示当前文档。它的大小等于词表数。首先tf是词频，也就是当前词在文档中出现的次数，通常会除以文档总词数来做归一化。idf的计算方法是log(语料库中总文档数 / 包含当前词的文档数)，可见分子是固定值，idf将随着包含当前词的文档数的增加而减小，也就是说常见词的idf值会相对较小，而当前文档比较有代表性的词发挥更大的作用。tf-idf的缺点是它是词袋模型，无法考虑词的位置信息，上下文信息以及一些分布特征。</p>
<h1 id="2、word2vec" class="heading-control"><a href="#2、word2vec" class="headerlink" title="2、word2vec"></a>2、word2vec<a class="heading-anchor" href="#2、word2vec" aria-hidden="true"></a></h1><p>实际上tf-idf就是one-hot的一种优化，还是存在维度灾难以及语义鸿沟的问题。因此后来的工作着重于构建<strong>分布式低维稠密词向量</strong>。word2vec就是它们的开山之作。我们知道NNLM（语言模型）是一种自监督训练的模型，用上文来预测下一个词的概率，那么词向量就可以作为它的副产物学习到这种基于序列共现的语境信息。word2vec基于这种思想提出了更专注于词向量学习的模型（比如舍弃隐藏层），用滑动窗口来指定固定大小的上下文，试图用当前词来预测上下文（skip-gram）或用上下文来预测当前词（CBOW）。具体细节可以参考<a href="https://arxiv.org/pdf/1411.2738.pdf" target="_blank" rel="noopener">这篇论文</a>。</p>
<p><strong>word2vec的两种加速训练策略</strong></p>
<ul>
<li><p>分层softmax<br>用哈夫曼树来计算词的概率，每个词对应一个叶节点。非叶节点也各自对应一个向量，词的概率可由它到根节点的唯一路径来计算。<br>哈夫曼树的构造方法：将词表中的每个词看作只有一个结点的树，用词频来表示它们的权重。选择根节点权重最小的两棵树合并，合并后的父节点权重等于两个子结点之和。下面是一个例子：</p>
<p><img src="https://img-blog.csdnimg.cn/20200225165605690.png#pic_center" alt><br>为了保证概率相加等于1，在路径上采用sigmoid来计算向左或向右（n表示结点，v表示结点向量）：</p>
</li>
</ul>
<script type="math/tex; mode=display">p(n, left) = \sigma (v^T\mathbf{h})</script><script type="math/tex; mode=display">p(n, right) = 1 - \sigma (v^T\mathbf{h}) = \sigma (-v^T\mathbf{h})</script><p>  那么某个词 $w_o$ 出现的概率就是：</p>
<p>  <img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200216224934.png" style="zoom: 50%;"><br>  [[·]]是个1/-1函数，左子结点取1，右子结点取-1。 再算cross entropy即可：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200216225025.png" style="zoom:50%;"><br>  这样就代替了softmax，复杂度从O(N)变成O(log N)。</p>
<ul>
<li><p>负采样</p>
<p>采样概率：在词频上取0.75次幂，减小词频差异带来的采样影响，即</p>
<script type="math/tex; mode=display">weight(w) = \frac{count(w)^{0.75}}{\sum_u count(u)^{0.75}}</script><p>那么损失函数为：</p>
<script type="math/tex; mode=display">E = -\log \sigma(v'^T_{w_o} \mathbf{h}) - \sum_{w_N \in NEG} \log \sigma(-v'^T_{w_N} \mathbf{h})</script><p><script type="math/tex">w_o</script> 是目标词，<script type="math/tex">w_I</script> 是输入词。对于skip-gram，<script type="math/tex">\mathbf{h} = v_{w_I}</script>，对于CBOW，<script type="math/tex">\mathbf{h} = \frac{1}{C}\sum_{c=1}^{C} v_{w_c}</script>。</p>
</li>
</ul>
<p>word2vec只能抽取局部特征，词的上下文信息局限于滑动窗口大小。</p>
<h1 id="3、GloVe" class="heading-control"><a href="#3、GloVe" class="headerlink" title="3、GloVe"></a>3、GloVe<a class="heading-anchor" href="#3、GloVe" aria-hidden="true"></a></h1><p>细节推荐<a href="https://blog.csdn.net/coderTC/article/details/73864097" target="_blank" rel="noopener">这篇博客</a>。主要的几个步骤包括：</p>
<ul>
<li><p>构建共现矩阵<br> GloVe指定特定大小的上下文窗口，通过滑动该窗口统计共现矩阵X（|V|*|V|），$X_{ij}$ 表示中心词i与上下文词j的共现次数。同时还定义了衰减函数，令距离为d的两个词在计数时乘以1/d。 </p>
</li>
<li><p>确定近似目标<br>作者发现可以用概率之比来建模共现关系。定义条件概率P:</p>
<script type="math/tex; mode=display">P_{ij} = P(j|i) = \frac{X_{ij}}{X_i}</script><p>表示词j出现在i上下文的概率。而用词k出现在i的上下文与它出现在j上下文的概率之比</p>
<script type="math/tex; mode=display">ratio_{i,j,k} = \frac{P_{ik}}{P_{jk}}</script><p>来表示i，j，k三个词之间的共现关系。当i，k和j，k相关程度近似时，该比率趋近于1；i，k相关度大于j，k相    关度时该比率值较大，反之则较小。GloVe的目标就是使学习到的词向量满足这样的规律，既有自身上下文信息，又能和其它词联系起来。目标函数：</p>
<script type="math/tex; mode=display">F(w_i,w_j,w_k) = \frac{P_{ik}}{P_{jk}}</script><p> 要同时满足三个词的约束关系，训练复杂度会变得很高。作者通过一系列变（硬）换（凑），把上式转换成了两个词的约束目标：</p>
<script type="math/tex; mode=display">\begin{aligned}
  F(w_i,w_j,w_k) &= \exp((w_i - w_j)^Tw_k) \\
                 &= \exp(w_i^Tw_k - w_j^Tw_k) \\
                 &= \frac{\exp (w_i^Tw_k)}{\exp (w_j^Tw_k)} =          \frac{P_{ik}}{P_{jk}}
  \end{aligned}</script><p>由此，</p>
<script type="math/tex; mode=display">P_{ik} = \exp (w_i^Tw_k)</script><p>成为新的目标函数。然而这种内积计算方式具有对称性，为了避免这种错误的性质，作者继续变（硬）换（凑）：</p>
<script type="math/tex; mode=display">P_{ik} = \frac{X_{ik}}{X_i} = \exp (w_i^Tw_k) \\
  \log P_{ik} = \log (X_{ik}) - \log X_i = w_i^Tw_k \\
  w_i^Tw_k + \log X_i = \log (X_{ik})</script><p>将$\log X_i$看作常数项，再添加一个偏置$b_k$，目标函数最终形式为：</p>
<script type="math/tex; mode=display">w_i^Tw_k + b_i + b_k = \log(X_{ik})</script><p>其中$X_{ik}$ 是共现矩阵中的值。</p>
</li>
<li><p>构造损失函数（平方损失）</p>
<script type="math/tex; mode=display">J = \sum_{i,k=1}^V f(X_{ik}) (w_i^Tw_k + b_i + b_k - \log(X_{ik}))^2</script><p>其中$f(X_{ij})$ 是关于共现矩阵的权重函数，</p>
<p>  <img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200216233258.png" style="zoom: 67%;"><br>也就是说，共现次数越少，对它们的相关性约束越小。</p>
</li>
</ul>
<p>推导过程见<a href="https://blog.csdn.net/coderTC/article/details/73864097" target="_blank" rel="noopener">这篇博客</a>或<a href="https://www.aclweb.org/anthology/D14-1162.pdf" target="_blank" rel="noopener">原论文</a>。</p>
<p><strong>Glove和Word2vec比较</strong></p>
<ul>
<li>word2vec面向局部特征，基于滑动窗口，而GloVe综合了全局语料。</li>
<li>word2vec可以增量学习，而Glove是由固定语料计算的共现矩阵。</li>
</ul>
<h1 id="4、Fasttext" class="heading-control"><a href="#4、Fasttext" class="headerlink" title="4、Fasttext"></a>4、Fasttext<a class="heading-anchor" href="#4、Fasttext" aria-hidden="true"></a></h1><p>Fasttext最早其实是一个文本分类算法，后续加了一些改进来训练词向量。概括了几点：</p>
<ul>
<li>fasttext在输入时对每个词加入了n-gram特征，在输出时使用分层softmax加速训练。</li>
<li>fasttext将整篇文章的词向量求平均作为输入得到文档向量，用文本分类做有监督训练，对输出进行softmax回归，词向量为副产品。</li>
<li>fasttext也可以无监督训练词向量，与CBOW非常相似。</li>
</ul>
<h1 id="5、ELMo" class="heading-control"><a href="#5、ELMo" class="headerlink" title="5、ELMo"></a>5、ELMo<a class="heading-anchor" href="#5、ELMo" aria-hidden="true"></a></h1><p>之前那些方法构造的都是独立于上下文的word embedding，也就是无论下游任务是什么，输入的embedding始终是固定的，这就无法解决一词多义，以及在不同语境下有不同表现的需求。所以后续的ELMo，GPT-2以及BERT都是针对于这类问题提出的，通过预训练和fine-tune两个阶段来构造context-dependent的词表示。</p>
<p>ELMo使用双向语言模型来进行预训练，用两个分开的双层LSTM作为encoder。biLM的loss是：</p>
<script type="math/tex; mode=display">
L = \sum_{k=1}^N (\log p(t_k|t_1,...,t_{k-1};\overrightarrow{\Theta}_{LSTM},\Theta_s) + \log p(t_k|t_{k+1},...,t_{N};\overleftarrow{\Theta}_{LSTM},\Theta_s))</script><p>其中$\Theta_s$ 是softmax层参数。作者认为第一层学到的是句法信息，第二层学到的是语义信息。这两层LSTM的隐状态以及初始的输入加权求和就得到当前词的embedding。ELMo还设置了一个参数，不同的下游任务可以取特定的值，来控制ELMo词向量起到的作用。总体来说第k个token得到的预训练embedding就是：</p>
<script type="math/tex; mode=display">
\mathbf{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^{L}s_j^{task} \mathbf{h}_{kj}^{LM}</script><p>在面对具体下游任务时，首先固定biLM的参数得到一个词表示，再与<strong>上下文无关的词表示</strong>（word2vec，或者charCNN获得的表示）拼接作为模型输入，在反向传播时fine-tune所有参数。</p>
<p>原文中提到的一些细节：</p>
<ul>
<li>biLM不同层的activation分布不同，在加权求和之前使用layer normalization有时会很有效。</li>
<li>增加dropout和L2正则化可能会有用，这对ELMo的权重提出了一个归纳偏差，使其接近所有biLM层的平均值。</li>
<li>在获得<strong>上下文无关词表示</strong>时，原文采用的方式是先用2048个charCNN卷积核做卷积，再过两层highway networks，然后用一个线性层把输出降到512维。</li>
</ul>
<h1 id="6、OpenAI-GPT" class="heading-control"><a href="#6、OpenAI-GPT" class="headerlink" title="6、OpenAI GPT"></a>6、OpenAI GPT<a class="heading-anchor" href="#6、OpenAI-GPT" aria-hidden="true"></a></h1><p>GPT和BERT与ELMo不同，ELMo使用LSTM作为编码器，而这两个用的是编码能力更强的Transformer。</p>
<p>GPT也是用语言模型进行大规模无监督预训练，但使用的是单向语言模型，也就是只根据上文来预测当前词。它实现的方式很直观，就是Transformer的decoder部分，只和前面的词计算self-attention来得到表示。在下游任务上，之前的ELMo相当于扩充了其它任务的embedding层，各个任务的上层结构各不相同，而GPT则不同，它要求所有下游任务都要完全与GPT的结构保持一致，只在输入输出形式上有所变化：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200218230527.png"></p>
<p>这是在NLP上第一次实现真正的端到端，不同的任务只需要定制不同的输入输出，无需构造内部结构。这样预训练学习到的语言学知识就能直接引入下游任务，相当于提供了先验知识。比如说人在做阅读理解时，先通读一遍全文再根据问题到文章中找回答，这些两阶段模型就类似这个过程。为了防止fine-tune时丢失预训练学到的语言知识，损失函数同时考虑下游任务loss（$L_2$）和语言模型loss（$L_1$）：</p>
<script type="math/tex; mode=display">
L_3(C) = L_2(C) + \lambda L_1(C)</script><p>个人认为GPT的最大创新：</p>
<ul>
<li>用足够复杂的模型结构担任不同NLP任务的中间框架，启发了统一的端到端实现策略。</li>
<li>第二阶段保留语言模型的loss。</li>
</ul>
<h1 id="7、BERT" class="heading-control"><a href="#7、BERT" class="headerlink" title="7、BERT"></a>7、BERT<a class="heading-anchor" href="#7、BERT" aria-hidden="true"></a></h1><p>推荐<a href="https://jalammar.github.io/illustrated-bert/" target="_blank" rel="noopener">这篇博客</a>（这位大佬的其它文章质量也超高，尤其Transformer那篇估计是好多人的入门必看）</p>
<p>GPT虽然效果很好，但它在预训练时使用的是transformer的decoder部分，也就是单向语言模型，在计算attention时只能看见前面的内容，这样embedding获得的上下文信息就不完整。ELMo虽然是双向语言模型，但实际上是分开执行再组合loss，这就会带来一定的损失。</p>
<h2 id="7-1-Bert预训练" class="heading-control"><a href="#7-1-Bert预训练" class="headerlink" title="7.1 Bert预训练"></a>7.1 Bert预训练<a class="heading-anchor" href="#7-1-Bert预训练" aria-hidden="true"></a></h2><p>与GPT不同的是，bert在预训练时除了语言模型loss以外，还增加了一个“next sentence prediction”任务，即两个句子组成sentence pair同时输入，预测第二句是否是第一个句子的下文，是一个二分类任务。</p>
<h3 id="7-1-1-输入" class="heading-control"><a href="#7-1-1-输入" class="headerlink" title="7.1.1 输入"></a>7.1.1 输入<a class="heading-anchor" href="#7-1-1-输入" aria-hidden="true"></a></h3><ul>
<li>每个位置的输入：<ul>
<li><code>wordpiece-token</code> 词向量，这里的wordpiece是将token拆分成子词。</li>
<li><code>position emb</code> 位置向量</li>
<li><code>segment emb</code> 句子标识，属于第一个句子则为0，第二个句子则为1</li>
</ul>
</li>
<li>整体输入：<code>[CLS]</code> ; sent1 ; <code>[SEP]</code>; sent2 ;<code>[SEP]</code></li>
</ul>
<h3 id="7-1-2-训练任务" class="heading-control"><a href="#7-1-2-训练任务" class="headerlink" title="7.1.2 训练任务"></a>7.1.2 训练任务<a class="heading-anchor" href="#7-1-2-训练任务" aria-hidden="true"></a></h3><ul>
<li><p>Masked Language Model</p>
<ul>
<li><p>所谓双向LM，就是在预测当前词时同时考虑上文和下文，也就是</p>
<script type="math/tex; mode=display">
p(t_k | t_1, ..., t_{k-1}, t_{k+1}, ...,t_N)</script><p>但LM是要逐词预测的，用这种概率计算方法会导致<strong>信息泄露</strong>，也就是当前词已经在之前的预测中作为下文而暴露了。作者由此提出了<strong>MASK</strong>策略，只选取15%的词进行预测，在输入时用[MASK]标记替代，而仍然以原词作为训练target。类似于阅读理解中的Cloze任务。当然，预测的词少了，模型收敛速度就会变慢，需要的训练step也要相应增加。</p>
</li>
<li><p>mask解决了信息泄露问题，但实际输入（也就是fine-tune阶段）不会包含这种标记，导致两阶段不一致，对训练效果产生影响。作者的解决方案是在这随机选取的15%词当中，80%的概率替换为[MASK]，10%的概率替换成其它词（负采样） ，10%的概率保留原词。这样有一个好处是，模型不知道当前要预测的词是否被篡改了，迫使其更关注上下文，学习到上下文相关的表示，这正是我们的目的。</p>
<p>作者还在附录里给出了一个扩展实验，对比不同的预训练mask策略对后续结果的影响：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200222142447.png" style="zoom: 80%;"><br>可以看到至少在这两个任务中，结果对不同的mask法是鲁棒的，差别不大。但从最后两条可以看出，直接去掉[MASK]，80%或100%取负样本的效果相比之下差了很多。按理说使用负样本相当于构建去噪自编码器，到底比MASK差在哪？思考了一下，原因很可能是负采样词作为其它词的上下文输入，使得这些词学到的embedding融合了错误的信息，对训练造成影响；而[MASK]本身并没有任何含义，它从未作为target出现过，也就没有特定的出现语境，因此其embedding没有实际意义，对其它词的影响也就相对较小。</p>
</li>
</ul>
</li>
<li><p>Next Sentence Prediction</p>
<p>0/1分类任务。从语料中选取两个片段AB（注意这里是两个“span”，而不是实际意义上的“句子”，因为希望输入尽可能长）作为一条输入，50%的概率AB连续（1），50%不连续（0）。输出在[CLS]处取FFNN+Softmax做二分类预测。输入的最大长度是512，超过则直接截断。</p>
</li>
</ul>
<h3 id="7-1-3-训练细节" class="heading-control"><a href="#7-1-3-训练细节" class="headerlink" title="7.1.3 训练细节"></a>7.1.3 训练细节<a class="heading-anchor" href="#7-1-3-训练细节" aria-hidden="true"></a></h3><ul>
<li><p>预训练数据及规模<br>BooksCorpus (800M words) 加 Wikipedia (2,500M words)</p>
</li>
<li><p>参数设置</p>
<ul>
<li>batch_size： 256 sequences(256*512 tokens) , step 1,000,000 (40 epochs on 3.3 billion word corpus)</li>
<li>Adam优化器。lr=1e-4，$\beta_1$=0.9，$\beta_2$=0.999，l2 weight decay=0.01</li>
<li>learning rate warmup：10,000 steps，lr线性缩减</li>
<li>所有层均设dropout=0.1</li>
<li>激活函数：gelu</li>
</ul>
</li>
<li><p>训练loss<br>masked LM与NSP的log likelihood之和</p>
</li>
</ul>
<h2 id="7-2-Bert-Fine-tune" class="heading-control"><a href="#7-2-Bert-Fine-tune" class="headerlink" title="7.2 Bert Fine-tune"></a>7.2 Bert Fine-tune<a class="heading-anchor" href="#7-2-Bert-Fine-tune" aria-hidden="true"></a></h2><p>fine-tuning的任务主要分成<strong>基于句子</strong>的和<strong>基于token</strong>的。基于句子的一般取[CLS]的embedding输出预测，基于token的则直接取对应位置的输出进行预测。</p>
<p>一般需根据特定的任务重新设置batch_size, learning rate, epochs超参数，其余与预训练保持一致即可。</p>
<h5 id="训练" class="heading-control"><a href="#训练" class="headerlink" title="训练"></a>训练<a class="heading-anchor" href="#训练" aria-hidden="true"></a></h5><p>fine-tuning的任务主要分成<strong>基于句子</strong>的和<strong>基于token</strong>的。基于句子的一般取[CLS]的embedding输出预测，基于token的则直接取对应位置的输出进行预测。</p>
<p>一般需根据特定的任务重新设置batch_size, learning rate, epochs超参数，其余与预训练保持一致即可。</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200222154051.png" style="zoom: 67%;"></p>
<p>预训练好的Bert除了用于fine-tuning以外，还可以像ELMo一样作为特征抽取器，也就是直接用学习到的word embeddings当做其它模型的输入。目前看来最好的选择是最后四层向量拼接。</p>
<p>Bert与GPT的区别：</p>
<ul>
<li>GPT与Bert训练数据不同，GPT使用BooksCorpus (800M words); BERT是BooksCorpus (800M words)加Wikipedia (2,500M words)。</li>
<li>GPT在预训练时没有[CLS]和[SEP]，在下游任务时才有</li>
<li>GPT在fine-tuning时加入LM的loss，而Bert是完全使用任务特定的目标函数。</li>
<li>GPT的lr在两阶段保持一致，Bert认为任务特定的lr效果更好</li>
</ul>
<p>Bert最大的创新：</p>
<ul>
<li>用mask策略实现了双向语言模型，非常巧妙。</li>
<li>预训练除了语言模型，还加入了next sentence prediction，试图学习更高层面的语言关联性。提供了很好的扩展思路。</li>
</ul>

      
    </div>

    

    
    
    

    

    
      
    
    
      <div>
        <div id="reward-container">
  <div>万一有人想不开就点了呢(๑ಠᴗಠ๑)</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">

    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/wx.jpg" alt="Yue Yuan 微信支付">
        <p>微信支付</p>
      </div>
    
      
      
        
      
      <div style="display: inline-block">
        <img src="/images/zfb.jpg" alt="Yue Yuan 支付宝">
        <p>支付宝</p>
      </div>
    

  </div>
</div>

      </div>
    

    
      <div>
        




  



<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Yue Yuan</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    
    <a href="http://anery.github.io/posts/a71e8abb.html" title="NLP词向量发展历程">http://anery.github.io/posts/a71e8abb.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/posts/556a9e21.html" rel="next" title="pytorch学习之nn.Embedding和nn.EmbeddingBag">
                <i class="fa fa-chevron-left"></i> pytorch学习之nn.Embedding和nn.EmbeddingBag
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80MzQ4MS8yMDAyMQ=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Yue Yuan">
            
              <p class="site-author-name" itemprop="name">Yue Yuan</p>
              <div class="site-description motion-element" itemprop="description">Take it easy</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives">
                
                    <span class="site-state-item-count">10</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/Anery" title="GitHub &rarr; https://github.com/Anery" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:yy137743057@gmail.com" title="E-Mail &rarr; mailto:yy137743057@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://blog.csdn.net/shunaoxi2313" title="CSDN &rarr; https://blog.csdn.net/shunaoxi2313" rel="noopener" target="_blank"><i class="fa fa-fw fa-globe"></i>CSDN</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://www.zhihu.com/people/fu-jian-qing-kuang" title="知乎 &rarr; https://www.zhihu.com/people/fu-jian-qing-kuang" rel="noopener" target="_blank"><i class="fa fa-fw fa-globe"></i>知乎</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1、tf-idf"><span class="nav-number">1.</span> <span class="nav-text">1、tf-idf</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2、word2vec"><span class="nav-number">2.</span> <span class="nav-text">2、word2vec</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3、GloVe"><span class="nav-number">3.</span> <span class="nav-text">3、GloVe</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4、Fasttext"><span class="nav-number">4.</span> <span class="nav-text">4、Fasttext</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5、ELMo"><span class="nav-number">5.</span> <span class="nav-text">5、ELMo</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6、OpenAI-GPT"><span class="nav-number">6.</span> <span class="nav-text">6、OpenAI GPT</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7、BERT"><span class="nav-number">7.</span> <span class="nav-text">7、BERT</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-Bert预训练"><span class="nav-number">7.1.</span> <span class="nav-text">7.1 Bert预训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-1-输入"><span class="nav-number">7.1.1.</span> <span class="nav-text">7.1.1 输入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-2-训练任务"><span class="nav-number">7.1.2.</span> <span class="nav-text">7.1.2 训练任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-3-训练细节"><span class="nav-number">7.1.3.</span> <span class="nav-text">7.1.3 训练细节</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-Bert-Fine-tune"><span class="nav-number">7.2.</span> <span class="nav-text">7.2 Bert Fine-tune</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#训练"><span class="nav-number">7.2.0.0.1.</span> <span class="nav-text">训练</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      
	  
	  
	    

		
		<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
		<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
		<div class="widget-wrap">
			<h3 class="widget-title">Tag Cloud</h3>
			<div id="myCanvasContainer" class="widget tagcloud">
				<canvas width="250" height="250" id="resCanvas" style="width=100%">
					<ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Graph/">Graph</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/">pytorch</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/技巧/">技巧</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/模式识别/">模式识别</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/用法记录/">用法记录</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/知识图谱/">知识图谱</a><span class="tag-list-count">1</span></li></ul>
				</canvas>
			</div>
		</div>
		
		
		 <div style>
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>


	 
    </div>	  
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yue Yuan</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.0.1</div>




    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>





        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  

  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  















  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script src="/lib/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.1"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.1"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'vUbfXc0NyB0Tq2zzexRrkhwA-gzGzoHsz',
    appKey: 'H241f9g1EjlUcNcJcJogpuak',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn'
  });
</script>




  
    <script>
  window.livereOptions = {
    refer: 'posts/a71e8abb.html'
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script>

  


  
  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  
  
  <script>
    
    function addCount(Counter) {
      var $visitors = $('.leancloud_visitors');
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
            Counter('put', '/classes/Counter/' + counter.objectId, JSON.stringify({ time: { '__op': 'Increment', 'amount': 1 } }))
            
              .done(function() {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.time + 1);
              })
            
              .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
              })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1 }))
                .done(function() {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function() {
                  console.log('Failed to create');
                });
            
          }
        })
        .fail(function ({ responseJSON }) {
          console.log('LeanCloud Counter Error: ' + responseJSON.code + ' ' + responseJSON.error);
        });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + 'vUbfXc0NyB0Tq2zzexRrkhwA-gzGzoHsz')
        .done(function({ api_server }) {
          var Counter = function(method, url, data) {
            return $.ajax({
              method: method,
              url: 'https://' + api_server + '/1.1' + url,
              headers: {
                'X-LC-Id': 'vUbfXc0NyB0Tq2zzexRrkhwA-gzGzoHsz',
                'X-LC-Key': 'H241f9g1EjlUcNcJcJogpuak',
                'Content-Type': 'application/json',
              },
              data: data
            });
          };
          
            addCount(Counter);
          
        });
    });
  </script>



  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
  

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });
  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') { next = next.nextSibling }
        if (next && next.nodeName.toLowerCase() === 'br') { next.parentNode.removeChild(next) }
      }
    });
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      document.getElementById(all[i].inputID + '-Frame').parentNode.className += ' has-jax';
    }
  });
</script>
<script src="//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
<script type="text/javascript" src="/js/src/hone_hone_clock.js"></script>
