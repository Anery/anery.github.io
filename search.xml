<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>pytorch学习之nn.Embedding和nn.EmbeddingBag</title>
    <url>/posts/556a9e21.html</url>
    <content><![CDATA[<p>关于pytorch中的embedding常用的主要有两个函数，这篇blog将从每个参数的含义入手，通过举例的方式比较两个方法的异同以及各自的使用场景。</p>
<a id="more"></a>
<p>从基础的nn.Embedding说起：</p>
<blockquote>
<p>CLASS torch.nn.Embedding(<strong>num_embeddings, embedding_dim,<br>padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None</strong>)</p>
</blockquote>
<p>num_embeddings, embedding_dim没啥好说的，就是look-up表的形状，我们在搭建网络时大多情况下只用得上这两个参数。下面具体看看剩下的参数能做什么：</p>
<ul>
<li>padding_idx<br>表示pad的序号。NLP项目中句子需pad成相同长度批量输入，此项即为填充项对应的index，对应的embedding为0.<br><img src="https://img-blog.csdnimg.cn/20191117233502400.png" alt></li>
<li>max_norm<br>用来约束embedding vector，把范数大于max_norm的vector重归一化，使之等于max_norm。</li>
<li>norm_type<br>p-norm的p值（0,1,2）<br>这两个参数基本不用了，现在都用kaiming和xavier初始化参数</li>
<li>scale_grad_by_freq<br>顾名思义，用词的频率来缩放梯度，即梯度除以这个词的出现次数。注意这里的词频指的是自动获取当前mini-batch中的词频，而非对于整个词典。</li>
<li>sparse<br>bool值，设置成True时参数weight为稀疏tensor。<br>所谓稀疏tensor是说反向传播时只更新当前使用词的embedding，加快更新速度。这里值得一提的是，即使设置sparse=True，embedding的权重也未必稀疏更新：（1）与优化器相关，使用momentumSGD、Adam等优化器时包含momentum项，导致不相关词的embedding依然会叠加动量，无法稀疏更新；（2）使用weight_decay，即正则项计入loss。</li>
</ul>
<p>好了，明白了Embedding的参数，再来看EmbeddingBag：</p>
<blockquote>
<p>CLASS torch.nn.EmbeddingBag(<strong>num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode=’mean’, sparse=False, _weight=None</strong>)</p>
</blockquote>
<p>官方API：</p>
<p> <a href="https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.htmlhighlight=embeddingbag#torch.nn.EmbeddingBag</a></p>
<p>参数只多了一个：mode，先来看这个参数的含义。</p>
<p>官网上说得很清楚，取值分三种，对应三种操作：”sum”表示普通embedding后接torch.sum(dim=0)，”mean”相当于后接torch.mean(dim=0)，”max”相当于后接torch.max(dim=0)。</p>
<p>只看这个参数就清楚了，EmbeddingBag就是把look-up表整合成一个embedding，当不需要具体查表获得embedding，只需要一个整合结果时，它比上述两阶段操作更高效。</p>
<p>来看它的输入：</p>
<ul>
<li><p>input (LongTensor)和offsets (LongTensor, optional)<br>input可以是2D或1D：</p>
<ul>
<li>input shape 2D (B,N)<br>相当于B个bag，每个bag长度固定为N，此时要求offsets参数为None。<br>输出分别对B个bag做整合，shape：(B, embedding_dim)</li>
<li>input shape 1D (N)<br>虽然是1D，但默认为多个bag平铺在了一起，因此offsets必须同时输入，表示每个bag的起始index，shape=(B)，再分别对每个bag整合。<br>输出shape：(B, embedding_size)</li>
</ul>
<p>说到这可以发现其实和类名一样，这就是个“词袋”操作，典型的应用场景是FastText，多个文档平铺成1D输入，再指定offsets，直接就可以进行批量不等长文档处理，写起来简单，效率又有提升。</p>
</li>
</ul>
<p>官方的例子：<br>    <img src="https://img-blog.csdnimg.cn/20191118222612392.png" alt></p>
<ul>
<li>per_sample_weights(Tensor, optional)<br>  该输入给每个实例一个权重再加权求和（此时mode只能为sum），与输入shape相同。<br>一个典型的应用场景是deepFM，某列特征对应的embedding有时需按照权重加和。</li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch中LSTM的细节分析理解</title>
    <url>/posts/f14fa36f.html</url>
    <content><![CDATA[<p>虽然看了一些很好的blog了解了LSTM的内部机制，但对框架中的lstm输入输出和各个参数还是没有一个清晰的认识，今天打算彻底把理论和实现联系起来，再分析一下pytorch中的LSTM实现。</p>
<a id="more"></a>
<p>先说理论部分。<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">一个非常有名的blog</a>把原理讲得很清楚，推荐参考。总之就是这些公式：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820143026202.png" alt></p>
<p>简单来说就是，LSTM一共有三个门，输入门，遗忘门，输出门，$i,f,o$分别为三个门的程度参数，$g$是对输入的常规RNN操作。公式里可以看到LSTM的输出有两个，细胞状态$c’$和隐状态$h’$，$c’$是经输入、遗忘门的产物，也就是当前cell本身的内容，经过输出门得到$h’$，就是想输出什么内容给下一单元。</p>
<p>那么实际应用时，我们并不关心细胞本身的状态，而是要拿到它呈现出的状态$h’$作为最终输出。以pytorch中的LSTM为例：</p>
<p><strong>torch.nn.LSTM(*args, **kwargs)</strong></p>
<p>官方API：<br><a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM</a></p>
<hr>
<ul>
<li>参数<br>— <strong>input_size</strong><br>— <strong>hidden_size</strong><br>— <strong>num_layers</strong><br>— <strong>bias</strong><br>— <strong>batch_first</strong><br>— <strong>dropout</strong><br>— <strong>bidirectional</strong></li>
</ul>
<hr>
<ul>
<li>输入<br>— <strong>input</strong>  (seq_len, batch, input_size)<br>— <strong>h_0</strong> (num_layers <em> num_directions, batch, hidden_size)<br>— <strong>c_0</strong> (num_layers </em> num_directions, batch, hidden_size)</li>
</ul>
<hr>
<ul>
<li>输出<br>— <strong>output</strong> (seq_len, batch, num_directions <em> hidden_size)<br>— <strong>h_n</strong> (num_layers </em> num_directions, batch, hidden_size)<br>— <strong>c_n</strong> (num_layers * num_directions, batch, hidden_size)</li>
</ul>
<hr>
<p>用起来很简单，当作黑箱时只要设置参数让它输出我们想要的shape就行了，但这些参数好像很难和前面公式里的那些联系起来，不便于理解和灵活使用。</p>
<p>先看一张很好的图（<a href="https://www.zhihu.com/question/41949741/answer/318771336" target="_blank" rel="noopener">LSTM神经网络输入输出究竟是怎样的？ - Scofield的回答 - 知乎</a>）：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820153259157.png" alt></p>
<p>这张图是以MLP的形式展示LSTM的传播方式（不用管左边的符号，输出和隐状态其实是一样的），方便理解hidden_size这个参数。其实hidden_size在各个函数里含义都差不多，就是参数W的第一维（或最后一维）。那么对应前面的公式，hidden_size实际就是以这个size设置所有W的对应维。</p>
<p>再看另一张很好的图（<a href="https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714%29" target="_blank" rel="noopener">https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714</a>）：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820152709292.png" alt></p>
<p>这张图非常便于理解参数num_layers。实际上就是个depth堆叠，每个蓝色块都是LSTM单元，只不过第一层输入是<script type="math/tex">x_t,h_{t-1}^{(0)},c_{t-1}^{(0)}</script>，中间层输入是<script type="math/tex">h_{t}^{(k-1)},h_{t-1}^{(k)},c_{t-1}^{(k)}</script>。</p>
<p>剩下的参数就比较好理解了，input_size即输入的隐层维度，比如embedding_dim。batch_first，第一维是否是batch，为什么要设置这个参数后面再说。bidirectional，是否为双向LSTM。</p>
<p>接下来看一下输入输出。关于input，API中提到也可以是一个packed变量序列，这个后面再讲。输入输出中$h$和$c$的shape (num_layers * num_directions, batch, hidden_size) 也是个容易困惑的点，但有了上面那张图就好说多了。绿色块$h_n,c_n$即长度为n的序列的最终输出，可以看出是所有depth输出的拼接，维度是num_layers。双向LSTM情况，相当于有两个图中的网络，只不过输入颠倒过来了，再将这两个最终隐状态拼接起来，维度num_layers*2。</p>
<p>最后看一下输出output。初学时看别人的代码，总是搞不清到底是取output还是用$h_n$，怎么用的都有。其实从图中可以看到，output就是最后一个layer上，序列中每个状态$h$的集合（若为双向则按位置拼接，输出维度2*hidden_size），所以$h_n$就是$output[-1,:,:]$。我们使用LSTM的目的是得到整个序列的embedding，与序列长度无关，由于LSTM具有序列信息传递性，因此一般都取$h_n$当作序列输出。但双向LSTM推广后，每个位置的隐层输出都可以作为当前词的一个融合了上下文的embedding，因此取output再以词粒度进行融合（比如attention加权求和、pooling）也是一种主流方法。</p>
<p>理论终于和实践联系起来了，下面来具体分析一下pytorch的LSTM实现。</p>
<h2 id="pytorch的LSTM" class="heading-control"><a href="#pytorch的LSTM" class="headerlink" title="pytorch的LSTM"></a>pytorch的LSTM<a class="heading-anchor" href="#pytorch的LSTM" aria-hidden="true"></a></h2><hr>
<p><strong>1、torch.nn.LSTMCell(input_size, hidden_size, bias=True)</strong></p>
<p>官方API：</p>
<p><a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTMCell" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTMCell</a>**</p>
<p>一个LSTM单元。相当于一个time step的处理，应该是对应TensorFlow里类似的实现。基本不用。</p>
<p><strong>2、torch.nn.LSTM(*args, **kwargs)</strong></p>
<p>官方API：</p>
<p><a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM</a></p>
<p>前面基本讲得差不多了，只剩下两处：参数batch_first和input的packed variable length sequence。</p>
<p>为什么要有batch_first这个参数呢？常规的输入不就是(batch, seq_len, hidden_size)吗？而且参数默认为False，也就是它鼓励你第一维不是batch，更奇怪了。</p>
<p>取pytorch官方的一个tutorial（<a href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html" target="_blank" rel="noopener">chatbot tutorial</a>）中的一个图：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820164135998.png" alt></p>
<p>左边是我们的常规输入（先不考虑hidden dim，每个数字代表序列中的一个词），右边是转置后，第一维成了max_length。我们知道在操作时第一维一般可视为“循环”维度，因此左边一个循环项是一个序列，无法同时经LSTM处理，而右边跨batch的循环项相当于当前time step下所有序列的当前词，可以并行过LSTM。（当然不管你是否batch_first它都是这么处理的，这个参数应该只是提醒一下这个trick）</p>
<h4 id="pack-amp-pad" class="heading-control"><a href="#pack-amp-pad" class="headerlink" title="pack&amp;pad"></a>pack&amp;pad<a class="heading-anchor" href="#pack-amp-pad" aria-hidden="true"></a></h4><p>（感觉说起来没那么简单，所以加了个小标题。）</p>
<p>前面说过nn.LSTM的输入也可以是“packed”形式，那么这是个什么形式？</p>
<p>先不问为什么，看一下pack和pad的操作是怎样的。</p>
<hr>
<p><strong>torch.nn.utils.rnn.pack_sequence(sequences, enforce_sorted=True)</strong></p>
<p>官方API：<a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pack_sequence" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pack_sequence</a></p>
<p>这是pack操作，输入的sequences是tensor组成的list，要求按长度从大到小排序。官网的例子：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820171602978.png" alt></p>
<hr>
<p><strong>torch.nn.utils.rnn.pad_sequence(sequences, batch_first=False, padding_value=0)</strong></p>
<p>官方API：</p>
<p><a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pad_sequence" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pad_sequence</a></p>
<p>这是pad操作，sequences也是list。这个比较好理解，就是给list里的tensor都用padding_value来pad成最长的长度，并组合成一个tensor：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820172338569.png" alt></p>
<p>看了这两个操作，隐隐约约和前面的LSTM联系起来了。我们知道一个batch里的序列不一定等长，需要pad操作用0把它们都填充成max_length长度。但前面说了LSTM的一次forward对应一个time step，接收的是across batches的输入，这就导致短序列可能在当前time step上已经结束，而你还是在给它输入东西（pad），这就会对结果产生影响（可以对照公式看看，即便输入全0还是会有影响）。我们想要的效果是，LSTM知道batch中每个序列的长度，等到某个序列输入结束后下面的time step就不带它了。</p>
<p>传统的pad不能用，LSTM需要一种其它的方法来处理变长输入。这时我们观察刚看到的pack操作，感觉终于明白了它的道理。官方的例子有点混淆，我写了一个更直观的：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820181026673.png" alt></p>
<p>把这个例子看成是LSTM处理一个batch的过程，注意看成转置的形式，即batch_first=False，也就是[4,1,9]是第一个序列，[5,2]是第二个序列…max_length=3，batch_size=5。从输出可以看出其实是一个很简单的过程，有点像稀疏矩阵的存储方法，先都塞到一起再记录位置（这里是长度）。</p>
<p>这两个函数都是基本操作，一般不会直接使用。常用的是下面这两个：</p>
<hr>
<p><strong>torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)</strong></p>
<p>官方API：</p>
<p><a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pack_padded_sequence" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pack_padded_sequence</a></p>
<p>顾名思义，pack一个经过pad的sequence，因为我们一般在处理数据时就已经将序列pad成等长了。lengths即为序列的长度。</p>
<hr>
<p><strong>torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None)</strong></p>
<p>官方API：</p>
<p><a href="https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pad_packed_sequence" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.utils.rnn.pad_packed_sequence</a></p>
<p>这是上面函数的逆操作，再pad回去供后续使用。这里的total_length是个很实用的参数，在下面的例子中可以看到。</p>
<hr>
<p>一个完整的例子：</p>
<p><img src="https://img-blog.csdnimg.cn/20190820203610836.png" alt><br><img src="https://img-blog.csdnimg.cn/20190820203739954.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20190820204233403.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> t</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_padded_sequence, pad_packed_sequence</span><br><span class="line"></span><br><span class="line">a = t.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">6</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">0</span>]]) <span class="comment">#(batch_size, max_length)</span></span><br><span class="line">lengths = t.tensor([<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排序</span></span><br><span class="line">a_lengths, idx = lengths.sort(<span class="number">0</span>, descending=<span class="literal">True</span>)</span><br><span class="line">_, un_idx = t.sort(idx, dim=<span class="number">0</span>)</span><br><span class="line">a = a[idx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义层 </span></span><br><span class="line">emb = t.nn.Embedding(<span class="number">20</span>,<span class="number">2</span>,padding_idx=<span class="number">0</span>) </span><br><span class="line">lstm = t.nn.LSTM(input_size=<span class="number">2</span>, hidden_size=<span class="number">4</span>, batch_first=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line">a_input = emb(a)</span><br><span class="line">a_packed_input = t.nn.utils.rnn.pack_padded_sequence(input=a_input, lengths=a_lengths, batch_first=<span class="literal">True</span>)</span><br><span class="line">packed_out, _ = lstm(a_packed_input)</span><br><span class="line">out, _ = pad_packed_sequence(packed_out)</span><br><span class="line"><span class="comment"># 根据un_idx将输出转回原输入顺序</span></span><br><span class="line">out = t.index_select(out, <span class="number">0</span>, un_idx)</span><br></pre></td></tr></table></figure>
<p>上面便是常用的使用方法（个人认为完全可以封装到LSTM函数里，不知道为什么要这么设计）。但此时假设另一个batch，b：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># b是另一个batch</span></span><br><span class="line">b = t.tensor([[<span class="number">7</span>,<span class="number">8</span>,<span class="number">0</span>],[<span class="number">9</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">10</span>,<span class="number">0</span>,<span class="number">0</span>]])</span><br></pre></td></tr></table></figure>
<p>batch中的最大长度为2，而对于整个数据流来说max_length=3，这就导致b经LSTM后pad的结果与整体的长度不匹配，此时设置pack_padded_sequence的total_length=3即可。</p>
<hr>
<p>有不正确的地方还请指正！</p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>conda 导出环境/导入环境/导出base环境</title>
    <url>/posts/dce5d55.html</url>
    <content><![CDATA[<p>conda的虚拟环境真的非常实用，尤其是对于大的深度学习项目，给每个项目单独配一个环境，轻巧又容易管理，还能直接用别人配好的虚拟环境，非常方便。这里记录几个常用的导入导出命令免得每次找。</p>
<a id="more"></a>
<p>查看可用环境：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda info --envs</span><br></pre></td></tr></table></figure></p>
<p>输出样式：</p>
<p><img src="https://img-blog.csdnimg.cn/20190614200754939.png" alt></p>
<p>更换环境（如py36）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source activate py36</span><br></pre></td></tr></table></figure>
<p>导出当前环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda env export &gt; py36.yaml</span><br></pre></td></tr></table></figure>
<p>会生成一个<code>py36.yaml</code>文件，将其复制到目标机上后执行导入环境操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda env create -f py36.yaml</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：若导出base环境，则在目标机上会提示已存在（而且base环境无法删除）。所以要想导出base，最好先复制一下，再导出复制品：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create -n new_name --clone base</span><br></pre></td></tr></table></figure>
<p>再导出new_name环境即可。必要的话再在原机删除复制环境：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda remove -n new_name --all</span><br></pre></td></tr></table></figure></p>
<p>在用的时候发现有些module还是未安装，上网找了下原因，原来以上只会导出conda命令直接安装的包，而我的包大多是用pip安装在Anaconda的lib和site-package里了。因此还要用导出pip的方法：</p>
<p>pip导出安装的库到<code>27.txt</code>：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip freeze &gt; 27.txt</span><br></pre></td></tr></table></figure></p>
<p>pip导入<code>27.txt</code>中列出的库到新机：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -r 27.txt</span><br></pre></td></tr></table></figure>
<p>其实就是按列表重新安装一遍，导出的列表可以自己先看一眼，筛掉一些脑抽安装的没用包</p>
]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>用法记录</tag>
      </tags>
  </entry>
  <entry>
    <title>transE(Translating Embedding)详解+简单python实现</title>
    <url>/posts/e68d7ca3.html</url>
    <content><![CDATA[<p><strong>表示学习</strong>旨在学习一系列低维稠密向量来表征语义信息，而<strong>知识表示学习</strong>是面向知识库中实体和关系的表示学习。当今大规模知识库（或称知识图谱）的构建为许多NLP任务提供了底层支持，但由于其规模庞大且不完备，如何高效存储和补全知识库成为了一项非常重要的任务，这就依托于知识表示学习。</p>
<p>transE算法就是一个非常经典的知识表示学习，用分布式表示（distributed representation）来描述知识库中的三元组。想象一下，这类表示法既避免了庞大的树结构构造，又能通过简单的数学计算获取语义信息，因此成为了当前表示学习的根基。</p>
<a id="more"></a>
<h1 id="1-transE算法原理" class="heading-control"><a href="#1-transE算法原理" class="headerlink" title="1 transE算法原理"></a>1 transE算法原理<a class="heading-anchor" href="#1-transE算法原理" aria-hidden="true"></a></h1><p>我们知道知识图谱中的事实是用三元组 $(h,l,t)$ 表示的，那么如何用低维稠密向量来表示它们，才能得到这种依赖关系呢？transE算法的思想非常简单，它受word2vec平移不变性的启发，希望$h+l≈t$（此为归纳偏差？）。</p>
<p>光有这一个约束可不够。想让$h+l≈t$，如何设置损失函数是个关键。我们发现表示学习都没有明显的监督信号，也就是不会明确告诉模型你学到的表示正不正确，那么想要快速收敛就得引入“相对”概念，即<strong>相对负例来说，正例的打分要更高</strong>，方法学名“<strong>negative sampling</strong>”。损失函数设计如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20190504222759459.png" alt></p>
<p>其中$(h’,l,t’)$称为corrupted triplet，是随机替换头或尾实体得到（非同时，其实也可以替换relation）。$\gamma$为margin。细看发现这就是SVM的soft margin损失函数，所以可以说，transE针对给定三元组进行二分类任务，其中负例是通过替换自行构造的，目标是使得最相近的正负例样本距离最大化。</p>
<p>论文中给出了详细的算法流程：</p>
<p><img src="https://img-blog.csdnimg.cn/20190504224500785.png" alt></p>
<p>其中距离度量方式有L1范数和L2范数两种。在测试时，以一个三元组为例，用语料中所有实体替换当前三元组的头实体计算距离$d(h’+l,t)$，将结果按升序排序，用正确三元组的排名情况来评估学习效果（同理对尾实体这样做）。度量标准选择hits@10和mean rank，前者代表命中前10的次数/总查询次数，后者代表正确结果排名之和/总查询次数。</p>
<p>还有一点值得一提，文中给了两种测试结果raw和filter，其动机是我们在测试时通过替换得到的三元组并不一定就是负例，可能恰巧替换对了（比如（奥巴马，总统，美国）被替换成了（特朗普，总统，美国）），那么它排名高也是正确的，把当前三元组挤下去也正常。<strong>（存疑：这样的话训练时是否也应当过滤corrupted triplet呢）</strong> 所以测试时在替换后要检查一下新三元组是否出现在训练集中，是的话就删掉，这就是filter训练方法（不检查的是raw）。</p>
<h1 id="2-transE算法的简单python实现" class="heading-control"><a href="#2-transE算法的简单python实现" class="headerlink" title="2 transE算法的简单python实现"></a>2 transE算法的简单python实现<a class="heading-anchor" href="#2-transE算法的简单python实现" aria-hidden="true"></a></h1><p>为了更好地理解（其实是因为看不懂别人的），用python简单实现了transE算法，使用数据集FB15k。这里记录一些细节和几个小坑。完整代码见<a href="https://github.com/Anery/transE" target="_blank" rel="noopener">github</a>。</p>
<h4 id="1-训练transE" class="heading-control"><a href="#1-训练transE" class="headerlink" title="1. 训练transE"></a>1. 训练transE<a class="heading-anchor" href="#1-训练transE" aria-hidden="true"></a></h4><ul>
<li>Tbatch更新：在update_embeddings函数中有一个deepcopy操作，目的就是为了批量更新。这是ML中mini-batch SGD的一个通用的训练知识，在实际编码时很容易忽略。</li>
<li>两次更新：update_embeddings函数中，要对correct triplet和corrupted triplet都进行更新。虽然写作$(h,l,t)$和$(h’,l,t’)$，但两个三元组只有一个entity不同（前面说了，不同时替换头尾实体），所以在每步更新时重叠的实体要更新两次（和更新relation一样），否则就会导致后一次更新覆盖前一次。</li>
<li>关于L1范数的求导方法：先对L2范数求导，逐元素判断正负，为正赋值为1，负则为-1。</li>
<li>超参选择：对FB15k数据集，epoch选了1000（其实不需要这么大，后面就没什么提高了），nbatches选了400（训练最快），embedding_dim=50, learning_rate=0.01, margin=1。</li>
</ul>
<h4 id="2-测试" class="heading-control"><a href="#2-测试" class="headerlink" title="2. 测试"></a>2. 测试<a class="heading-anchor" href="#2-测试" aria-hidden="true"></a></h4><ul>
<li>isFit参数：区分raw和filter。filter会非常慢。</li>
</ul>
<h1 id="3-transE算法的局限性" class="heading-control"><a href="#3-transE算法的局限性" class="headerlink" title="3  transE算法的局限性"></a>3  transE算法的局限性<a class="heading-anchor" href="#3-transE算法的局限性" aria-hidden="true"></a></h1><p>transE效果很好且非常简单，后续大量的工作都是在此基础上的改进（简称trans大礼包），传统方法已经基本不用了（有些思想还是值得借鉴的，比如矩阵分解、双线性模型）。改进大体针对以下几个问题：</p>
<ul>
<li><strong>复杂关系建模效果差</strong>。对1-N,N-1,N-N关系，会出现冲突映射，一个实体在不同三元组内的表示融合，导致不明确甚至错误的语义信息。</li>
<li><strong>多源信息融合。</strong> 如何充分利用知识库中的额外信息（如实体类型、实体描述）。</li>
<li><strong>关系路径建模</strong>。 对relation之间的依赖进行建模。</li>
</ul>
<p>理解或实现有错误欢迎指出！</p>
<p>参考文献：</p>
<p>[1] Bordes A, Usunier N, Garcia-Duran A, et al. Translating embeddings for modeling multi-relational data[C]//Advances in neural information processing systems. 2013: 2787-2795.</p>
<p>[2] 刘知远, 孙茂松, 林衍凯, et al. 知识表示学习研究进展[J]. 计算机研究与发展, 2016, 53(2):247-261.</p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>Graph</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>主成分分析(PCA)的推导与理解</title>
    <url>/posts/b160a645.html</url>
    <content><![CDATA[<h3 id="一、PCA简介" class="heading-control"><a href="#一、PCA简介" class="headerlink" title="一、PCA简介"></a>一、PCA简介<a class="heading-anchor" href="#一、PCA简介" aria-hidden="true"></a></h3><p>主成分分析（PCA）是一种常见的，也是最简单的降维手段，在机器学习中可用于特征提取。即便有时收集到的样本维数很高（即含有过多特征），但与学习任务相关的可能只是某个低维分布，这时就需要有效降维，在缓解维数灾难的同时令得到的低维嵌入仍能很好地描述原样本空间。</p>
<a id="more"></a>
<h3 id="二、PCA推导" class="heading-control"><a href="#二、PCA推导" class="headerlink" title="二、PCA推导"></a>二、PCA推导<a class="heading-anchor" href="#二、PCA推导" aria-hidden="true"></a></h3><p>首先进行任务描述。</p>
<p>设样本 $X∈R^{n \times d}$ , 低维表示$Z∈R^{n \times l} (l&lt;d)$ 。$Z=X \times W$。可以将这个变换看作坐标变换，那么$W$就是$l$个正交基向量（列向量）组成的矩阵，$W^TW=I$。也就是说，我们有n个d维的原样本x，经坐标变换后得到n个$l$维的新样本z。在新坐标系中，$Z$的每一行（即每个新样本）都可看作是原样本在$w_i$方向上的<strong>投影</strong>。为了更直观地进行坐标变换，我们将样本进行中心化，每个样本都减去均值，使得样本中心落在原点，$\sum_i{x_i=0}$。</p>
<p>我们知道投影可以用内积的形式表示，用$x_iw_1$表示$x_i$（行向量）在$w_1$上的投影长度（还要除以$w_1$的模，这里为基向量，模长为1）。在信号处理中，认为信号的方差较大，噪声方差较小，这个理论可以推广到我们的问题中，也就是希望投影后的样本点比较分散（方差大），如下图（网图侵删）：</p>
<p><img src="https://img-blog.csdnimg.cn/20181203105105902.png" alt></p>
<p>认为第一个投影方向更好，它使得样本投影方差最大。由于样本已中心化，因此方差可用投影长度的均方来表示：<script type="math/tex">\frac{1}{n}\sum_i^n{(x_iw_1)^2}</script><br>上式取极大就是PCA目标函数的一种形式，利用的是最大方差准则（也可以用最小二乘等准则）。其中$w_1$是要求的第一个投影方向（主方向，对应着W的某一列）。$x_iw_1$是一个标量，它的转置等于本身，目标函数可写成如下形式：</p>
<script type="math/tex; mode=display">
\frac{1}{n}\sum_i^n{(x_iw_1)^T(x_iw_1)} \\
=\frac{1}{n}\sum_i^n{w_1^Tx_i^Tx_iw_1} \\
=\frac{1}{n}w_1^T(\sum_i^n{x_i^Tx_i} )w_1</script><p><strong>（注：这种方式是机器学习中常用的一种变换，将向量乘积根据需要灵活地结合成矩阵或标量，引入一些可解释性）</strong></p>
<p>显然中间部分就是协方差矩阵（$x_i$是行向量）。为了更形式化地表示，直接用$X$代替，并加上之前说的正交基假设，写出完整的目标函数：</p>
<script type="math/tex; mode=display">
max \quad \frac{1}{n}w_1^T(XX^T)w_1 \qquad
s.t. \quad w_1^Tw_1=1</script><p>是一个约束最优化问题，可引入拉格朗日乘子求解。这里补充一句，我们的目标函数包含一个标准二次型，之所以有最优解是因为它是半正定的（协方差矩阵是半正定矩阵）。目标函数中的$\frac{1}{n}$对结果无影响，在计算时不考虑。引入拉格朗日乘子λ：</p>
<script type="math/tex; mode=display">
L=w_1^T(XX^T)w_1-\lambda(w_1^Tw_1-1)</script><p>对参数求偏导得：</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial{w_1}}=0</script><script type="math/tex; mode=display">
(XX^T)w_1=\lambda w_1</script><p>可以看出，为了求目标函数极大，拉格朗日乘子$\lambda$就是协方差矩阵的特征值，我们要求的投影方向向量$w_1$是该特征值对应的特征向量。上面等式两边同时乘$w_1^T$得：</p>
<script type="math/tex; mode=display">
w_1^T(X^TX)w_1=\lambda</script><p>得到的式子左边就是我们的目标函数，那么目标函数可转换为</p>
<script type="math/tex; mode=display">
max \quad \lambda</script><p>至此，我们将求最大投影方差问题转换成了求协方差矩阵最大特征值的问题。上面是用一个投影向量$w_1$为例，为了求得d个投影向量组成的变换矩阵W，只需求最大d个特征值对应的特征向量即可。</p>
<p>得到了$W$以后，我们就可以对样本进行降维处理得到$Z:Z=XW$。</p>
<h3 id="三、总结" class="heading-control"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结<a class="heading-anchor" href="#三、总结" aria-hidden="true"></a></h3><p>上面经过严格的目标函数推导，我们得出了主成分分析的求解方法。可以看出这个结果非常“巧合”地映射到了协方差矩阵的特征向量上，使得这个过程有了可解释性。</p>
<p>因为$l&lt;d$,很显然这是一个有损变换。从任务角度来说，我们在特征提取时舍弃了$d-l$个特征，造成了信息丢失。为了减少损失，在降维过程中应尽量舍弃那些用处不大的特征。</p>
]]></content>
      <categories>
        <category>模式识别</category>
      </categories>
      <tags>
        <tag>模式识别</tag>
      </tags>
  </entry>
  <entry>
    <title>谱聚类基本方法详解</title>
    <url>/posts/7631c563.html</url>
    <content><![CDATA[<font color="#0099" size="4" face="微软雅黑">谱聚类是一种用图论思想解决聚类问题的手段。</font>

<a id="more"></a>
<h1 id="一、背景" class="heading-control"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景<a class="heading-anchor" href="#一、背景" aria-hidden="true"></a></h1><h2 id="1-1-一些图论的知识" class="heading-control"><a href="#1-1-一些图论的知识" class="headerlink" title="1.1 一些图论的知识"></a>1.1 一些图论的知识<a class="heading-anchor" href="#1-1-一些图论的知识" aria-hidden="true"></a></h2><p>首先定义无向图$G(V,E)$的几个基本概念：</p>
<p>1、<strong>邻接矩阵</strong>$W$，是一个$n \times n$的对称方阵。<br>2、顶点的<strong>度矩阵</strong>$D$，是一个$n \times n$的对角矩阵，对角线元素为对应顶点的度。是由邻接矩阵各行元素累加至主对角得到的。如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20181203160433813.png" alt></p>
<p>当图G的边带有权重时，可将权重视为顶点间的相似度，$W$转换为相似度矩阵，顶点的度转换为连接它所有边的权重之和。<br>3、子图$A$的<strong>势</strong>$|A|$等于图的所有顶点数。<br>4、子图$A$的<strong>体积</strong> $vol(A)$ 等于所有顶点的度之和。<br>5、<strong>边割</strong>表示边的集合，去掉这些边将导致原图变成两个连通子图，如下图红边就是一个边割：</p>
<p><img src="https://img-blog.csdnimg.cn/20181203222736810.png" alt></p>
<p>6、用子图<strong>相似度</strong>来度量两个子图的相似程度，定义为连接两个子图的所有边的权重之和。显然，边割的权重之和就是它分割的两个连通子图的相似度。<br>7、<strong>最小二分切割</strong>是导致两个子图相似度最小的切割方案，又称最小代价切割。它的目标函数如下：   </p>
<p>​                               <img src="https://img-blog.csdnimg.cn/20181203224132268.png" alt></p>
<p>（从这个优化目标中已经能看出图切割任务与聚类非常相似）</p>
<p>通常为了防止切割出一个野点的情况，需给目标函数加上约束条件，尽量使两个子图规模相差不要太大。这叫做归一化最小二分切割。</p>
<p><img src="https://img-blog.csdnimg.cn/20181203223909294.png" alt></p>
<h2 id="1-2-拉普拉斯矩阵" class="heading-control"><a href="#1-2-拉普拉斯矩阵" class="headerlink" title="1.2 拉普拉斯矩阵"></a>1.2 拉普拉斯矩阵<a class="heading-anchor" href="#1-2-拉普拉斯矩阵" aria-hidden="true"></a></h2><p>下面引出<strong>拉普拉斯矩阵</strong>：</p>
<script type="math/tex; mode=display">L=D-W</script><p>由定义可知，拉普拉斯矩阵的行和为0。除此之外这个矩阵还有几个非常有用的性质：</p>
<ul>
<li><p>有1个特征值为0，它对应的特征向量元素全是1。</p>
<p>$L \cdot \vec1=(D-W) \cdot \vec1=\vec0=0 \cdot \vec1$</p>
</li>
</ul>
<ul>
<li><p>$L$是半正定矩阵</p>
<p>  <img src="https://img-blog.csdnimg.cn/20181203230613556.png" alt></p>
</li>
</ul>
<ul>
<li>$L$的特征值与图的连通分量数目的关系：设 G 为一个具有非负连接权重的无向图，它的拉普拉斯矩阵 L 零特征值的重数等于图 G 的连通子图个数 k。</li>
</ul>
<p>下面分两种情况证明第三条性质。</p>
<p>① k=1，即G是一个连通图，需证明的是对应的L只有一重0特征值。</p>
<p>设$\vec{f}$是0特征值对应的特征向量，则$L\vec{f}=0\vec{f}=\vec0$ , $\vec{f^T}L\vec{f}=\vec0$，<script type="math/tex">\sum_{i,j=1}^nw_{ij}(f_i-f_j)^2=0</script>（见上面正定二次型的证明）</p>
<p>所以$f_i=f_j$。这个关系将随着连通路径进行传递，也就是说特征向量$\vec{f}$的所有元素都相等，处在元素全是1的基向量张成的空间。为了满足等式，显然无法找出分量不全相等的特征向量，因此0特征值对应的特征向量只有1个。证毕。</p>
<p>② k&gt;1，需证明L有k重0特征值。<br>将结点按连通子图进行编号，由于不同的连通子图之间不存在边相连，因此拉普拉斯矩阵L具有分块的结构：</p>
<p><img src="https://img-blog.csdnimg.cn/20181203231659103.png" alt></p>
<p>每个$L_i$都是一个独立的拉普拉斯矩阵。由①证得的结论可知，图G有k重0特征值，它们对应的特征向量是对应连通子图节点位置元素为1，其余位置全为0的向量。</p>
<font color="#0099ff" size="4" face="微软雅黑">这里可以看出，如果图G的连通子图对应k个聚类，那么它的拉普拉斯矩阵0特征值对应的特征向量就可以视为聚类结果，即对应位置为1的点处在一个聚类当中。</font>

<p>由此引出谱聚类。</p>
<h1 id="二、谱聚类" class="heading-control"><a href="#二、谱聚类" class="headerlink" title="二、谱聚类"></a>二、谱聚类<a class="heading-anchor" href="#二、谱聚类" aria-hidden="true"></a></h1><p>从广义上讲，任何在学习过程中应用到<strong>矩阵特征值分解</strong>的方法都可以成为<strong>谱学习方法</strong>，比如PCA、LDA等。<strong>谱聚类</strong>算法的本质就是将聚类问题转换成图的顶点划分问题，从上面介绍的图分割目标函数的形式就可以看出这是非常相似的两个任务。了解了上述的相关图论知识后，谱聚类可以很简单地描述出来。</p>
<p>将聚类问题映射到图分割问题后，我们希望子图之间相似性较小，即边割权重之和尽量小，子图内部权重之和尽量大。</p>
<p>显然首先要做的事，也是最关键的一步，就是将我们的样本点构造成图的形式。一般分为全连接、k近邻和$\epsilon$邻域三种（后两种类似kNN、parzon窗方法）。如果数据可分性很高，就可以直接对拉普拉斯矩阵进行特征值分解，k个0特征值对应的特征向量即为聚类结果，如下图的一个例子：</p>
<p><img src="https://img-blog.csdnimg.cn/20181203233658737.png" alt></p>
<p>但事实上我们在做聚类时数据不会如此规范，一般具有黏连性，这就需要在数据稀疏的地方划出聚类边界。这种黏连性会导致拉普拉斯矩阵只有一重0特征值，无法得出聚类结果，因此可以考虑松弛情况。</p>
<p>假设聚类数目k已知，若没有k重0特征值，则考虑最小的k个特征值，它们更接近0。虽然它们对应的特征向量不再像0特征值的那样规整又自带分类效果，但这些向量也反映了数据本身的特征（这就是矩阵分解，也就是谱学习所带来的好处。特征值和特征向量描述了矩阵的本质特征，也就涵盖了图中样本的内在特征）。用这n个k维向量进行k-means聚类，即可得出结果。</p>
<p>由于最终还是应用了k-means方法，我们可以将之前的步骤看成一个<strong>表示学习、特征选择</strong>的过程，也就是用选取的特征向量代替样本点的坐标值，再进行常规的k-means距离度量。</p>
<p>除此之外，谱聚类还有两个扩展方法，称为Normalized Spectral Clustering。主要是变换了拉普拉斯矩阵的形式，能够达到更好的效果。这里不再详述，感兴趣的话可以去搜一下<strong>归一化图拉普拉斯</strong>。</p>
<h1 id="三、总结" class="heading-control"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结<a class="heading-anchor" href="#三、总结" aria-hidden="true"></a></h1><p>谱聚类利用图论的方法解决聚类问题，非常的简单直观。我觉得这种思想非常有启发性。因为我研究的是NLP方向，因此在想矩阵特征向量能否表达自然语言里的一些主要含义？最近还听说了一种图CNN算法，可以当成一种开拓思路。</p>
]]></content>
      <categories>
        <category>模式识别</category>
      </categories>
      <tags>
        <tag>模式识别</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯决策类条件概率密度估计：最大似然和贝叶斯参数估计</title>
    <url>/posts/86fca59a.html</url>
    <content><![CDATA[<p><strong>有监督参数估计是指已知分类器结构或函数形式，从训练样本中估计参数。</strong>   </p>
<p>本文主要介绍贝叶斯决策（详见<a href="https://anery.github.io/posts/296fd81e.html">贝叶斯决策的过程</a>）条件概率密度的有监督参数估计过程。方法有最大似然估计和贝叶斯参数估计法。</p>
<a id="more"></a>
<h1 id="最大似然估计" class="heading-control"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计<a class="heading-anchor" href="#最大似然估计" aria-hidden="true"></a></h1><h2 id="假设参数为确定值，根据似然度最大进行最优估计。" class="heading-control"><a href="#假设参数为确定值，根据似然度最大进行最优估计。" class="headerlink" title="假设参数为确定值，根据似然度最大进行最优估计。"></a>假设参数为确定值，根据似然度最大进行最优估计。<a class="heading-anchor" href="#假设参数为确定值，根据似然度最大进行最优估计。" aria-hidden="true"></a></h2><p>给定数据</p>
<script type="math/tex; mode=display">D_1,D_2...D_c</script><p>表示不同类别的样本。假设每类样本独立同分布（i.i.d. 万年不变的假设），用$D_i$来估计$θ_i$，即对每个类求一个判别函数，用该类的样本来估计判别函数的参数。</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145720.png#pic_center" alt> </p>
<p>注意区分特征空间和参数空间。参数估计的任务是得到$p(x|w_i)$的形式，是在参数空间进行的。不妨设特征空间为d维，参数空间p维。<br>为了估计参数，需要如下几个步骤：</p>
<ul>
<li><p>求似然（Likelihood）<script type="math/tex">p(D|θ) =\prod_{k=1}^{n}p(x_k|θ)</script>  注意，上面这个式子针对的已经是具体的类别$w_i$了，不要问$w$参数去哪了。另外，这里的n代表样本数目，要和前面的类别数目c区分开。这个式子很好理解，即出现我们当前观测到的样本概率，求使它最大化的参数即可。</p>
</li>
<li><p>最大化似然 <script type="math/tex">\max_θp(D|θ)→\bigtriangledown_{\theta}p(D|θ)=0</script><br>这个梯度是在p维参数空间求解，即 </p>
<script type="math/tex; mode=display">
\bigtriangledown_{\theta}p=
\begin{bmatrix}
\frac{\partial}{\partialθ_1}\\
...\\
...\\
\frac{\partial}{\partialθ_p}
\end{bmatrix}</script></li>
<li><p>求解梯度。可求解析解或梯度下降。（常用Log-Likelihood，易求解）</p>
</li>
</ul>
<p>  <img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145842.png" alt></p>
<p>  <img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130150200.png" alt></p>
<p>  当先验$P(\theta)$都相等时等同于最大后验概率（MAP）决策。</p>
<h2 id="高斯密度最大似然估计" class="heading-control"><a href="#高斯密度最大似然估计" class="headerlink" title="高斯密度最大似然估计"></a>高斯密度最大似然估计<a class="heading-anchor" href="#高斯密度最大似然估计" aria-hidden="true"></a></h2><p>以<a href="https://anery.github.io/posts/296fd81e.html">贝叶斯决策过程</a>里给出的高斯密度假设为例，对它进行最大似然参数估计。首先假设$\sigma$已知，对$\mu$进行估计。</p>
<p>单点情况：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145900.png" alt></p>
<p>对于所有样本：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145906.png" alt></p>
<p>估计值即为观测样本均值。</p>
<p>再来看$\mu$和$\sigma$都未知的情况。设数据服从一维高斯分布，$\theta_1=\mu$，$\theta_2=\sigma^2$:</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145911.png" alt></p>
<p>令梯度等于0可求得：</p>
<script type="math/tex; mode=display">\hat{μ}=\frac{1}{n}\sum_{k=1}^nx_k</script><script type="math/tex; mode=display">\hat{σ}^2=\frac1{n}\sum_{k=1}^n(x_k-\hat{μ})^2</script><p>多维情况，$\theta_2=\Sigma$：</p>
<script type="math/tex; mode=display">\hat{μ}=\frac{1}{n}\sum_{k=1}^nx_k</script><script type="math/tex; mode=display">\hat{\Sigma}=\frac1{n}\sum_{k=1}^n(x_k-\hat{μ})(x_k-\hat{μ})^T</script><p>估计结果类似无偏估计。</p>
<h1 id="贝叶斯参数估计" class="heading-control"><a href="#贝叶斯参数估计" class="headerlink" title="贝叶斯参数估计"></a>贝叶斯参数估计<a class="heading-anchor" href="#贝叶斯参数估计" aria-hidden="true"></a></h1><h2 id="参数被视为随机变量，估计其后验分布" class="heading-control"><a href="#参数被视为随机变量，估计其后验分布" class="headerlink" title="参数被视为随机变量，估计其后验分布"></a>参数被视为随机变量，估计其后验分布<a class="heading-anchor" href="#参数被视为随机变量，估计其后验分布" aria-hidden="true"></a></h2><p>我们先来简化一下贝叶斯决策的条件概率密度形式。考虑训练样本对分类决策的影响，后验概率可写作：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145917.png" alt></p>
<p>首先由于先验概率一般可以事先得到，因此通常不考虑样本对它的影响。其次，我们使用的是有监督学习，训练样本自然都会分到各自所属的类中。基于这两点可简化公式，得到<strong>公式一</strong>：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145922.png" alt></p>
<p>由此我们需处理的其实是c个独立的问题，那么条件概率密度可简写成c个$P(x|D)$，分别对它们进行估计。</p>
<p>下面引出参数分布估计的过程。假定参数形式已知，即已知$p(x|θ)$，为求$p(x|D)$:</p>
<script type="math/tex; mode=display">p(x|D)=\int{p(x,θ|D)}dθ \\  \qquad\qquad \qquad=\int{p(x|θ,D)p(θ|D)dθ}</script><p>由于测试样本x（观测样本）和训练样本D的选取是独立的，因此可写成<strong>公式二</strong>：</p>
<script type="math/tex; mode=display">\quad p(x|D)=\int{p(x|θ)p(θ|D)dθ}</script><p>样本独立性是《模式分类第二版》里对这步变换做出的解释。对这一部分说一下我的理解。按书里说的x与D相互独立，那p(x|D)其实直接就可以简写成p(x)，且$p(\theta)$也假定已知（后面会说），直接</p>
<script type="math/tex; mode=display">\quad p(x)=\int{p(x|θ)p(θ)dθ}</script><p>不就能求了，为什么非要对条件概率密度引入D呢？</p>
<p>其实这样做的目的就是为了<strong>强行引入</strong>$p(\theta|D)$。别忘了$p(x|D)$实际上是$p(x|\omega,D)$，来自<strong>公式一</strong>。回顾一下公式一引入D的原因，是<strong>尽可能地利用已有的全部信息来估计后验概率$p(\omega|x)$</strong>，对$p(x|D)$也是这样。即便训练样本对观测值x没有影响，但我们希望再引入一个受样本影响的reproducing density $p(\theta|D)$，让它影响类条件概率的分布。其实相当于重新构造了一个先验，并希望$p(\theta|D)$在$\theta$的真实值附近有显著的尖峰（sharp）。通常可以用这个sharp逼近的$\hat\theta$来替代真实值，有$p(x|D) ≈ p(x|\hat\theta)$。如果估计值的置信度不高（用高斯分布来说即方差较大，sharp不明显。后面会说），也可以按$p(\theta|D)$对$\theta$进行采样，带入$p(x|\theta)$求平均：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145928.png" alt></p>
<p>总结一下，<strong>公式一</strong>和<strong>公式二</strong>是贝叶斯决策和参数估计的两个核心部分。尤其是<strong>公式二</strong>，我们希望把$p(x|D)$和$p(θ|D)$联系起来，那么已有的训练样本就能通过$p(θ|D)$对$p(x|D)$施加影响。<strong>至此我们已经把有监督学习问题（原始分类问题）转换成了一个无监督的概率密度预测问题（估计$p(θ|D)$）</strong>。</p>
<h2 id="高斯密度贝叶斯估计" class="heading-control"><a href="#高斯密度贝叶斯估计" class="headerlink" title="高斯密度贝叶斯估计"></a>高斯密度贝叶斯估计<a class="heading-anchor" href="#高斯密度贝叶斯估计" aria-hidden="true"></a></h2><p>对高斯密度假设进行贝叶斯参数估计。</p>
<p>考虑一维情况。$p(x|\mu)\sim N(μ，σ^2)$，假设$σ^2$已知，为了预测$p(μ|D)$，写成：</p>
<script type="math/tex; mode=display">p(μ|D)=\frac{p(D|μ)p(μ)}{\int{p(D|μ)p(μ)dμ}}</script><p>由于$p(D|\mu)=\prod_{k=1}^np(x_k|μ)$，则</p>
<script type="math/tex; mode=display">p(μ|D)=\alpha\prod_{k=1}^np(x_k|μ)p(μ)</script><p>$\alpha$是原式分母，作为常数项。</p>
<p>假设$p(μ)\sim N(μ_0，σ_0^2)$，$\mu_0$和$\sigma_0^2$已知。可以把$\mu_0$看作对$\mu$的先验估计，$\sigma_0^2$看作估计的不确定程度。做正态分布假设只是为了简化后面的数学运算。这一步的重点在于<strong>在参数估计过程中我们是已知参数先验概率密度$p(\mu)$的。</strong></p>
<p>公式展开：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145937.png" alt></p>
<p>与μ无关的因子都被归入$\alpha$中。可见$p(μ|D)$仍符合高斯分布，对照标准形式<script type="math/tex">p(μ|D)=\frac{1}{\sqrt{2\pi}σ_n}exp(-\frac{1}{2}\frac{(\mu-μ_n)^2}{σ_n^2})</script>可得</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145944.png" alt></p>
<p>到目前为止，已经把先验知识$p(\mu)$和训练样本信息$\hat\mu_n$结合在一起，估计出了后验概率$p(\mu|D)$。把结果直观地写在一起：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145949.png" alt></p>
<p>在这个结果中，$\mu_n$表示在观测到n个样本后，对参数$\mu$真实值的最好估计，$\sigma_n^2$则代表这个估计的不确定性（前面对先验假设也是这么解释的，理解一下高斯分布对参数估计的理论意义）。$\sigma_n^2$随着n的增大而减小，即增加训练样本后，对$\mu$真实估计的置信度将逐渐提高，呈现一个<strong>sharp</strong>。这样的过程称为贝叶斯学习过程。</p>
<p>将$p(\mu|D)$代入</p>
<script type="math/tex; mode=display">p(x|D)=\int{p(x|μ)p(μ|D)dμ}</script><p>得出$p(x|D)\sim{N(μ_n，σ^2+σ_n^2)}$。因此，根据已知的$p(x|μ)\sim{N(μ，σ^2)}$，只要用$μ_n$替换μ，$σ^2+σ_n^2$替换$σ^2$即可完成参数估计。</p>
<p>我们观察到，当n趋于无穷时，贝叶斯参数估计与最大似然效果相同。（当然在实际问题当中样本往往是有限的，这里只是形式化地理解）</p>
<p>总结一下贝叶斯估计的一般过程：</p>
<p>  <img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130145954.png" alt></p>
<h1 id="最大似然和贝叶斯估计的比较" class="heading-control"><a href="#最大似然和贝叶斯估计的比较" class="headerlink" title="最大似然和贝叶斯估计的比较"></a>最大似然和贝叶斯估计的比较<a class="heading-anchor" href="#最大似然和贝叶斯估计的比较" aria-hidden="true"></a></h1><p>在上面的例子中，用贝叶斯参数估计与ML分别对条件概率密度$p(x|\omega)$进行估计，得到的虽然都是高斯分布形式，但这个过程中做的假设是完全不同的。ML直接假定$p(x|\omega)$符合高斯分布，根据训练样本选取确定的参数$\hat\mu$和$\hat\sigma^2$。而贝叶斯估计方法是通过假设已知$p(x|θ)$和$p(\mu)$符合高斯分布，推出$p(\mu|D)$符合高斯分布， 进而根据<strong>公式二</strong>推出$p(x|D)$符合高斯分布。这个分布的sharp作为估计的均值，随样本数增加而改变，且确信度逐渐升高。</p>
<p>高斯分布的例子相对来说有点抽象，《模式分类》里还给了一个简单的例子，比较好理解，尤其是这幅图：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/20200130150032.png" alt></p>
<p>非常有助于理解。贝叶斯估计在样本最大值之外还有一个拖尾，这就是考虑了先验$p(\theta)$的结果，告诉我们在x=10附近，条件概率密度仍可能不为0。<em>（详见书中例1 递归的贝叶斯学习）</em></p>
<p>总的来说，最大似然估计根据训练样本明确估计出最优参数值，而贝叶斯估计目标是求出参数的分布，类似于“参数为0.5的概率为0.8”。虽然在估计时模糊的结果（即近似正确）往往更有用，但贝叶斯估计计算复杂度较高，可理解性较差，因此最大似然估计应用更广泛。</p>
]]></content>
      <categories>
        <category>模式识别</category>
      </categories>
      <tags>
        <tag>模式识别</tag>
      </tags>
  </entry>
  <entry>
    <title>深度神经网络排错实践指南</title>
    <url>/posts/48f17f8a.html</url>
    <content><![CDATA[<p>深度学习排错指南，主要内容翻译自<a href="http://t.cn/EtUAfzl" target="_blank" rel="noopener">此PPT</a>，选取了自己认为有用的部分记录。</p>
<a id="more"></a>
<h3 id="模型表现差的原因：" class="heading-control"><a href="#模型表现差的原因：" class="headerlink" title="模型表现差的原因："></a>模型表现差的原因：<a class="heading-anchor" href="#模型表现差的原因：" aria-hidden="true"></a></h3><ul>
<li>implementation bugs</li>
<li>hyperparameter choices</li>
<li>Data/model fit 实验数据质量</li>
<li>dataset construction: 数据不够，类别不均衡，标签噪声，训练和测试集分布不同</li>
</ul>
<h3 id="debug困难原因：" class="heading-control"><a href="#debug困难原因：" class="headerlink" title="debug困难原因："></a>debug困难原因：<a class="heading-anchor" href="#debug困难原因：" aria-hidden="true"></a></h3><ul>
<li>很难知道是否有bug</li>
<li>错误来源很多</li>
<li>结果对超参数和数据集组成的小改变很敏感</li>
</ul>
<h3 id="troubleshooting策略：" class="heading-control"><a href="#troubleshooting策略：" class="headerlink" title="troubleshooting策略："></a>troubleshooting策略：<a class="heading-anchor" href="#troubleshooting策略：" aria-hidden="true"></a></h3><p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1561450332641.png" alt></p>
<ul>
<li>start simple： 选择最简单的模型和数据</li>
<li>implement&amp;debug：若能跑起来，试图在一个批次上过拟合 &amp; 重现一个简单、已知的结果（关于过拟合后面详述）</li>
<li>evaluate：用bias-variance分解来决定下一步</li>
<li>tune hyper-parameters：用由粗到细随机搜索</li>
<li>improve model/data：若欠拟合，让模型变大；若过拟合，增加数据和正则项</li>
</ul>
<p>下面用例子来一步步说明。</p>
<p>假设你已经有：</p>
<ul>
<li>初始测试集</li>
<li>一个待提升的评估指标</li>
<li>基于human-level performance的目标表现，公开结果，先前的baseline，等等。</li>
</ul>
<p>比如：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1561451044291.png" alt></p>
<ol>
<li><p><strong>Starting simple</strong></p>
<ul>
<li><p>先选一个简单的结构：</p>
<p>| 你的输入数据 |      Start       |       下一步考虑       |<br>| :—————: | :———————: | :——————————: |<br>|     图像     |      LeNet       |         ResNet         |<br>|   文本序列   | 一层隐藏层的LSTM | Attention模型或WaveNet |<br>|     其它     | 一层隐藏层的FCN  |       视问题而定       |</p>
<p>特殊情形：多种输入模式，如image caption</p>
</li>
<li><p>用合理的默认值</p>
<ul>
<li><p>Optimizer：Adam，学习率3e-4</p>
</li>
<li><p>Activations：ReLu（FC和CNN），tanh（LSTMs）</p>
</li>
<li><p>Initialization：He et al. normal (used for relu) , Glorot normal (used for tanh) （Glorot normal即为Xavier初始化，pytorch里有，或TensorFlow里的 tf.glorot_normal_initializer ）</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1561452521433.png" alt></p>
</li>
<li><p>Regulazation：无（可不用）</p>
</li>
<li><p>Data normalization：无</p>
</li>
</ul>
</li>
<li><p>输入归一化：减均值除方差</p>
</li>
<li><p>简化问题：</p>
<ul>
<li>从一个小训练集开始（&lt;10000个实例）</li>
<li>用固定的objects数量，类数量，更小的图像尺寸，等等</li>
<li>创建一个更简单的人工合成训练集</li>
</ul>
</li>
</ul>
<p>针对前面那个例子就是：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1561453222714.png" alt></p>
</li>
<li><p><strong>Implement &amp; debug</strong></p>
<p>==<strong>在展开说这部分之前，作者总结了5个最常见的DL bug，可以先逐个排查：</strong>==</p>
<p>（1）tensor的shape出错（深表同感），直接报错shape错误就不说了，相对容易排查，需要注意的是能跑起来的错误，一般由广播策略引起。如 x.shape = (None,) , y.shape = (None,1)，(x+y).shape = (None,None)</p>
<p>（2）预处理输入出错（原文：Pre-processing inputs incorrectly，有点没理解）。比如，忘记归一化，或预处理过多</p>
<p>（3）损失函数接收的输入出错。比如，对期望收到logits的损失函数输入了softmax结果。</p>
<p>（4）忘记设置train/eval mode。有些策略在train和test时有不同的实现。</p>
<p>（5）数值不稳定，出现Inf/nan。通常源于使用exp、log或div操作。</p>
<p>==<strong>在实现模型时的一些建议：</strong>==</p>
<p>（1）轻量级实现。少加新代码，实现少于200行（经验）</p>
<p>（2）使用封装好的组件，如Keras。在具体实现上，使用<code>tf.layers.dense(…)</code> 替代 <code>tf.nn.relu(tf.matmul(W, x))</code>，使用<code>tf.losses.cross_entropy(…)</code>替代具体实现。（我个人认为在学习阶段更重要的是快速实现想法和按自己的需求改模型，所以Keras和pytorch可能是更好的选择。）</p>
<p>（3）以后再学习构造复杂的data生成pipeline。先从可以全部load到内存的数据开始。</p>
</li>
</ol>
<ul>
<li><p>让模型跑起来</p>
<p>常见错误：</p>
<ul>
<li><p>shape不匹配。</p>
<p><strong>常见原因：</strong>（1）sum,average,softmax操作在错误的维度（2）卷积层后忘记展平tensor（3）忘记去掉多余的“1“维度，如 (1,1,4) （4）存在磁盘上的数据类型与load时不符，比如存了个float64的numpy array，load的是float32。</p>
<p><strong>解决：</strong>开debugger，逐步进行模型创建和测试</p>
</li>
<li><p>数据类型错误。</p>
</li>
<li><p>OOM。</p>
<p><strong>常见原因：</strong>（1）tensor太大。一般是因为（evaluation时）batch size过大，或庞大的全连接层。（2）数据太多。load太多数据到内存，而不是用输入队列；或为创建数据集分配过大的buffer。（3）冗余的操作。可能在一个Session里创建了太多模型，或重复调用某个操作。</p>
<p>（4）有人占了你的卡（其实这条最实用）</p>
<p><strong>解决：</strong>逐项删掉占用内存密集的操作。</p>
</li>
<li><p>其它。</p>
<p><strong>常见原因：</strong> 忘记初始化变量；Forgot to turn off bias when using batch norm（这条不清楚什么意思？）</p>
<p><strong>解决：</strong>使用标准debugg工具包，如stack overflow和交互式debugger</p>
</li>
</ul>
<p>不同的框架有不同的debugger，pytorch的ipdb比较简单，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> ipdb; ipdb.set_trace()</span><br></pre></td></tr></table></figure>
<p>作者给出的两种使用方法：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1561628632132.png" alt></p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1561628644818.png" alt></p>
<p>不是很明确，用到的时候再搜一下用法。</p>
</li>
</ul>
<ul>
<li><p>在一个batch上过拟合</p>
<p>常见错误：</p>
<ul>
<li><p>error上升</p>
<p><strong>常见原因：</strong>（1）loss function或梯度的符号反了    （2）学习率太高    （3）softmax时对应的维度出错</p>
</li>
<li><p>error爆炸</p>
<p><strong>常见原因：</strong>（1）数值问题，检查exp、log和div操作    （2）学习率太高</p>
</li>
<li><p>error震荡</p>
<p><strong>常见原因：</strong>（1）数据或标签出错，如zeroed，错误shuffled，预处理出错    （2）学习率太高</p>
</li>
<li><p>error平稳</p>
<p><strong>常见原因：</strong>（1）学习率太低    （2）梯度没有传递给整个模型（梯度消失）    （3）太多正则化    （4）loss function的输入出错（比如，输入了softmax而不是logits）    （5）数据或标签出错</p>
</li>
</ul>
</li>
<li><p>与已知结果比较</p>
<p>作用由高到低：</p>
<ul>
<li><p>在你用的数据集上有官方模型实现</p>
<p>可按行输出中间结果，看是否有相同输出。</p>
</li>
<li><p>在benchmark上有官方模型实现</p>
<p>可按行输出中间结果，看是否有相同输出。</p>
</li>
<li><p>非官方模型实现</p>
</li>
<li><p>paper结果（只能对比预期指标）</p>
</li>
</ul>
</li>
</ul>
<ol>
<li><p><strong>Evaluate</strong></p>
<p>一般认为：<strong>Test error = irreducible error（无法消除的误差项） + bias + variance + val overfitting</strong></p>
<p>但前提是训练、验证、测试数据服从相同分布，如果出现下面这种情况：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1563710877694.png" alt></p>
<p>称为分布偏差（distribution shift），由于验证集一般是从训练集中选择的，因此与训练集具有同分布。此时验证集的结果并没有泛化到测试集的能力。</p>
<p>此时：<strong>Test error = irreducible error + bias + variance + ==distribution shift== + val overfitting</strong></p>
</li>
<li><p><strong>Improve model/data</strong></p>
<p>优先考虑bias-variance tradeoff：解决欠拟合、解决过拟合、解决distribution shift、平衡数据集</p>
<ul>
<li>解决欠拟合（降低偏差）<ul>
<li>让模型变得“更大”，横向增加hidden size，纵向增加layers</li>
<li>减少正则项</li>
<li>误差分析</li>
<li>选择不同的模型结构（如从LeNet转到ResNet）</li>
<li>调整超参</li>
<li>增加features</li>
</ul>
</li>
<li>解决过拟合（降低方差）<ul>
<li>增加训练数据（可能的话）</li>
<li>增加normalization（如batch norm，layer norm）</li>
<li>数据增强（data augmentation）</li>
<li>增加正则项（dropout，L2，权重衰减）</li>
</ul>
</li>
<li>解决distribution shift（优先级从高到低）<ul>
<li>分析test-val set的误差，收集更多训练数据来补偿</li>
<li>分析test-val set的误差，合成更多训练数据来补偿</li>
<li>将领域适应技术应用于训练集和测试集分布（Apply domain adaptation techniques to training &amp; test distributions）。什么是domain adaptation？就是在源分布上训练完后，只用无标注数据或有限的标注数据将模型泛化到目标分布。可以理解为迁移学习。</li>
</ul>
</li>
<li>平衡数据集</li>
</ul>
</li>
<li><p><strong>Tune hyperparameters</strong></p>
<p>经验法则：</p>
<p><img src="https://raw.githubusercontent.com/Anery/MyBlogPics/master/1563876305090.png" alt></p>
<ul>
<li><p>人工调参</p>
<p>首先要理解算法，理解每个超参的作用。比如，更高的learning rate意味着学得更快，但会降低学习的稳定性。其次就是不断训练和验证模型，用经验去“猜”更好的超参数，或手动选择参数范围。</p>
</li>
<li><p>grid search</p>
<p>自动枚举各种参数组合。但效率很低。</p>
</li>
<li><p>随机搜索</p>
<p>随机设置参数组合，选择表现好的一个区域，再次随机搜索，缩小范围。一般可以选到很好的超参数，<strong>实际中最常用。</strong></p>
</li>
<li><p>贝叶斯超参数优化</p>
</li>
</ul>
</li>
</ol>
<h3 id="结论" class="heading-control"><a href="#结论" class="headerlink" title="结论"></a>结论<a class="heading-anchor" href="#结论" aria-hidden="true"></a></h3><ul>
<li>DL debugger很难，因为错误来源非常广</li>
<li>为了得到bug-free的模型，我们应当把模型构建过程当作一个迭代过程</li>
</ul>
<h3 id="learn-more" class="heading-control"><a href="#learn-more" class="headerlink" title="learn more"></a>learn more<a class="heading-anchor" href="#learn-more" aria-hidden="true"></a></h3><ul>
<li>Andrew Ng’s book Machine Learning Yearning (<a href="http://www.mlyearning.org/" target="_blank" rel="noopener">http://www.mlyearning.org/</a>)</li>
<li>The following Twitter thread:  <a href="https://twitter.com/karpathy/status/1013244313327681536" target="_blank" rel="noopener">https://twitter.com/karpathy/status/1013244313327681536</a></li>
<li>This blog post:  <a href="https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neuralnetworks/" target="_blank" rel="noopener">https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neuralnetworks/</a></li>
</ul>
]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯决策的过程</title>
    <url>/posts/296fd81e.html</url>
    <content><![CDATA[<h1 id="最小风险决策" class="heading-control"><a href="#最小风险决策" class="headerlink" title="最小风险决策"></a>最小风险决策<a class="heading-anchor" href="#最小风险决策" aria-hidden="true"></a></h1><p>最小风险决策是贝叶斯决策的一般形式。引入决策代价loss：<script type="math/tex">\lambda_{ij}=\lambda (\alpha_i|\omega_j)</script> ，表示原本属于类 $j$，被错分为类 $i$ 所产生的风险（BTW，<script type="math/tex">\lambda_{ij}</script> 与 <script type="math/tex">\lambda_{ji}</script> 并不相等，有时相差很大。比如肿瘤检测时)。则条件风险 <script type="math/tex">R(\alpha_i|x) = \sum_{j=1}^{c}\lambda(\alpha_i|\omega_j)P(\omega_j|x)</script> 贝叶斯决策就要选择最小化该条件风险的类别 $i$。</p>
<p>当 $\lambda$ 为0/1损失时，$R(\alpha_i|x) = 1 - P(\omega_i|x)$，最小风险决策退化为最小错误率决策，或最大后验决策。</p>
<a id="more"></a>
<h1 id="带拒识的决策" class="heading-control"><a href="#带拒识的决策" class="headerlink" title="带拒识的决策"></a>带拒识的决策<a class="heading-anchor" href="#带拒识的决策" aria-hidden="true"></a></h1><p>在很多模式识别应用中，当最大后验也不是很高，也就是置信度低的情况下，很可能出现了不可分情况，可让分类器拒绝分类。设计拒识风险 $\lambda_r$，表示为：</p>
<p>​                                <img src="https://img-blog.csdnimg.cn/20181227202031326.png" alt></p>
<p>则风险$R$表示为：</p>
<p>​                              <img src="https://img-blog.csdnimg.cn/20181227202242274.png" alt></p>
<p>可知当$\lambda_s[1 - P(\omega_i|x)] &gt; \lambda_r$时选择拒识，决策方式写作：</p>
<p>​                 <img src="https://img-blog.csdnimg.cn/20181227202640209.png" alt></p>
<p>这种写法比较形式化，可以简单的理解$\max P(\omega_i|x)$小于某个阈值时视为置信度过低，拒绝分类。</p>
<h1 id="贝叶斯决策具体过程" class="heading-control"><a href="#贝叶斯决策具体过程" class="headerlink" title="贝叶斯决策具体过程"></a>贝叶斯决策具体过程<a class="heading-anchor" href="#贝叶斯决策具体过程" aria-hidden="true"></a></h1><p>前面定义了贝叶斯决策的风险函数，主要与类别后验相关。根据贝叶斯公式$P(\omega_i|x) = \frac{P(x|\omega_i)P(\omega_i)}{P(x)}$，给出贝叶斯决策的几种判别函数：</p>
<p>​                         $g_i(x) = P(\omega_i|x)$ ，$g_i(x) = P(x|\omega_i)P(\omega_i)$，$g_i(x) = -R(\alpha_i|x)$</p>
<p>还有一种常用的似然形式：$g_i(x) = \log P(x|\omega_i) + \log P(\omega_i)$</p>
<p>则判别决策为$\arg\max g_i(x) $。令判别函数相等可得到决策面，能够在几何上对特征空间进行分割，让我们对分类有直观的认识，加深对分类器的理解。</p>
<p>贝叶斯决策几个关键步骤：</p>
<blockquote>
<p>1、估计类条件概率密度$P(x|\omega_i)$</p>
<p>2、估计类先验概率$P(\omega_i)$   (一般从训练数据中统计)</p>
<p>3、决策代价$\lambda_{ij}$。（除非面向特定应用，否则一般用0/1损失，即最大后验决策）</p>
</blockquote>
<h2 id="类条件概率密度估计方法" class="heading-control"><a href="#类条件概率密度估计方法" class="headerlink" title="类条件概率密度估计方法"></a>类条件概率密度估计方法<a class="heading-anchor" href="#类条件概率密度估计方法" aria-hidden="true"></a></h2><blockquote>
<p>1、<strong>参数法。</strong>假定概率密度函数形式，如高斯分布。</p>
<p>2、<strong>非参数法</strong>。如Parzen窗，k-NN。</p>
<p>3、<strong>半参数法。</strong>高斯混合。</p>
</blockquote>
<h3 id="高斯密度函数法" class="heading-control"><a href="#高斯密度函数法" class="headerlink" title="高斯密度函数法"></a>高斯密度函数法<a class="heading-anchor" href="#高斯密度函数法" aria-hidden="true"></a></h3><p>假定类条件概率密度符合高斯分布，那么只要估计出均值和协方差矩阵即可得到$p(x|\omega_i)$。参数估计过程详见<a href="https://anery.github.io/posts/86fca59a.html">最大似然和贝叶斯参数估计</a>。</p>
<p>将条件概率分布写成多元高斯形式:</p>
<p>​                         <img src="https://img-blog.csdnimg.cn/2018122817162463.png" alt></p>
<p>得到似然形式的判别函数$g_i(x)$：</p>
<p>​                 <img src="https://img-blog.csdnimg.cn/20181228171706393.png" alt></p>
<p>在数据的不同分布情况下，我们能得到一些特殊的形式。下面根据协方差矩阵的3种形式（逐渐推广），直观地来看一下数据分布、先验等对贝叶斯决策的影响。</p>
<ul>
<li><p><strong>Case 1</strong>  <script type="math/tex">\Sigma_i =\sigma^2</script></p>
<p>  协方差矩阵是对角矩阵，且对角元素相等。这种情况说明数据在各个维度（或说特征，对应特征空间）上的分布独立，且各个维度的方差均为<script type="math/tex">\sigma^2</script>。从几何上来说，所有类的样本分别落在一个形状相同的超球体当中。判别函数用于分类，因此只考虑类别相关的部分，即与i相关的项，其余部分不考虑，判别函数写成：</p>
<p>  <img src="https://img-blog.csdnimg.cn/20181228172944726.png" alt></p>
<p>  将二范数平方展开，得到</p>
<p>  <img src="https://img-blog.csdnimg.cn/20181228173017703.png" alt></p>
<p>  注意到<script type="math/tex">x^tx</script>与类别无关，可不考虑。为了直观地获得一般形式的决策超平面，我们将判别函数写成线性形式：</p>
<p>  <img src="https://img-blog.csdnimg.cn/20181228173209664.png" alt></p>
<p>  以二分类情况为例，令<script type="math/tex">g_i(x)-g_j(x)=0</script>即可得到决策面，表示为：</p>
<p>  <img src="https://img-blog.csdnimg.cn/2018122817323655.png" alt><br>  <img src="https://img-blog.csdnimg.cn/20181228173245467.png" alt></p>
<p>  我们观察到，法向量等于两类类心点的差，因此<strong>决策面与两个中心点连线垂直</strong>。决策面与这条直线相交于点<script type="math/tex">x_0</script>。</p>
<p>  再来观察<script type="math/tex">x_0</script>，当先验概率相等即<script type="math/tex">P(\omega_i)=P(\omega_j)</script>时，<script type="math/tex">x_0</script>第二项为0，那么该点落在两中心点连线的中心，如图（图来自《模式分类第二版》）</p>
<p>  <img src="https://img-blog.csdnimg.cn/20181228173826942.png" alt></p>
<p>  当先验不相等时，决策面将随着点<script type="math/tex">x_0</script>向先验概率小的方向偏移，如下图</p>
<p>  <img src="https://img-blog.csdnimg.cn/20181228173917124.png" alt></p>
<p>  这里给出的是比较极端的一种情况，先验相差较大，<script type="math/tex">P(\omega_1)=0.9,P(\omega_2)=0.1</script>。这就使得决策面偏移很大，甚至没有落在两个均值向量之间，可见<strong>先验概率对分类结果也有很大的影响。当然，当<script type="math/tex">\sigma^2</script>远小于<script type="math/tex">||\mu_i-\mu_j||^2</script>时，<script type="math/tex">x_0</script>第二项将变得很小，使决策面对先验不再敏感。</strong></p>
</li>
<li><p><strong>Case 2</strong>  <script type="math/tex">\Sigma_i =\Sigma</script></p>
<p>各个类的协方差矩阵相同，但均值各不相同。这显然是Case 1的一个推广。</p>
<p>首先同样只保留类别相关项，即</p>
<p>​                          <img src="https://img-blog.csdnimg.cn/20181228174726102.png" alt></p>
<p>将判别函数按照与刚才同样的方法转换成一般形：</p>
<p>​               <img src="https://img-blog.csdnimg.cn/20181228174850582.png" alt><br>​         <img src="https://img-blog.csdnimg.cn/20181228174858387.png" alt="img"></p>
<p>再得到决策面：</p>
<p>​                           <img src="https://img-blog.csdnimg.cn/20181228174822129.png" alt></p>
<p>​                       <img src="https://img-blog.csdnimg.cn/20181228174835112.png" alt></p>
<p>我们再来看这种形式。首先，法向量经一个矩阵变换，使得决策面不再垂直于两中心点连线，但仍与直线交于点$x_0$。当先验概率相等时，$x_0$位于连线中点，否则依然偏向先验小的一类。如下图所示。</p>
<p>​                        <img src="https://img-blog.csdnimg.cn/20181228171607649.png" alt></p>
<p>由于协方差矩阵不再是对角矩阵，各个维度相互依赖，使得样本分布的形状呈椭球形，而不再是标准的球形。但由于各类协方差矩阵相同，因此它们的分布形状都是一样的。可以观察一下，<strong>决策面的方向其实与椭球最长轴的方向一致，这与协方差矩阵的几何性质有关，主成分分析（PCA）也利用了这一点。</strong></p>
</li>
<li><p><strong>Case 3</strong>  <script type="math/tex">\Sigma_i</script>任意</p>
<p>这是最一般的情况，各个类的样本分布形状各不相同，由贝叶斯判别边界求出的决策面也不再是超平面，而成为了超曲面。</p>
<p>《模式分类第二版》里给出了几个直观的2D情况的例子：</p>
<p>​                <img src="https://img-blog.csdnimg.cn/20181228180649875.png" alt></p>
<p>总结一下，列出这三种情况其实就是为了说明数据分布情况对高斯情况下决策的影响。<strong>这些图也帮助我们理解了协方差矩阵是如何反映数据分布的</strong>。</p>
</li>
</ul>
<h3 id="分类错误率" class="heading-control"><a href="#分类错误率" class="headerlink" title="分类错误率"></a>分类错误率<a class="heading-anchor" href="#分类错误率" aria-hidden="true"></a></h3><p>考虑二分类，决策面把特征空间分成$R_1$和$R_2$两个部分，那么错误分类的情况发生在真实类为$\omega_1$，观测值落在R2中，或真实类为$\omega_2$，观测值落在$R_1$中时。形式化表示为：</p>
<p>​                     <img src="https://img-blog.csdnimg.cn/20181228183104960.png" alt></p>
<p>推广到一般形式，计算正确率更为方便：</p>
<p>​                          <img src="https://img-blog.csdnimg.cn/20181228183452415.png" alt></p>
<p>再来考虑最大后验概率决策，即0/1损失的情况：</p>
<p>​                      <img src="https://img-blog.csdnimg.cn/20181228183614756.png" alt></p>
<h1 id="总结" class="heading-control"><a href="#总结" class="headerlink" title="总结"></a>总结<a class="heading-anchor" href="#总结" aria-hidden="true"></a></h1><p>贝叶斯分类器使用的是最小错误率决策，理论情况下，即条件概率密度函数和风险$\lambda$被正确估计时是最优分类器。然而通常我们都仅仅是假设了条件概率密度函数的形式，如前面所述的高斯分布，导致效果出现偏差。事实上这里有两层误差，一个是结构误差，即对真实样本分布的错误估计，另一个是模型参数估计误差。这两层误差是造成贝叶斯分类器效果不好的原因，而并非分类器本身的缺陷。</p>
]]></content>
      <categories>
        <category>模式识别</category>
      </categories>
      <tags>
        <tag>模式识别</tag>
      </tags>
  </entry>
</search>
